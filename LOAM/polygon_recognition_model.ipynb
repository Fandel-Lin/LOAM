{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For training '''\n",
    "#import argparse\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from loam.evaluate import evaluate\n",
    "from loam.loam_model import LOAM\n",
    "from loam.utils.data_loading import BasicDataset, CarvanaDataset\n",
    "from loam.utils.dice_score import dice_loss\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import math\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For predicting '''\n",
    "#import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from loam.utils.data_loading import BasicDataset\n",
    "from loam.loam_model import LOAM\n",
    "from loam.utils.utils import plot_img_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' For performance evaluating '''\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy import sparse\n",
    "import pyvips\n",
    "\n",
    "# Code moved to validation_evaluation_worker.py\n",
    "import validation_evaluation_worker\n",
    "\n",
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "multiprocessing.set_start_method('spawn', True)\n",
    "PROCESSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_new_dataset = True # Set to [True] if one wants to filter a new dataset\n",
    "filtering_threshold = 0.25 # An image must have more than [0.25] labeled pixels to be filtered as a valid image candidate for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_testing = 8 # can set to any values...\n",
    "separate_validating_set = False\n",
    "reading_predefined_testing = True\n",
    "training_needed = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup auxiliary information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_info_source = Path('data/auxiliary_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_info = np.genfromtxt(auxiliary_info_source, delimiter=',', dtype=None, encoding='utf8')\n",
    "print(auxiliary_info.shape)\n",
    "print(auxiliary_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliary_dict_indexed = {}\n",
    "for info_index in range(1, auxiliary_info.shape[0]):\n",
    "    auxiliary_dict_indexed.update({auxiliary_info[info_index, 1] : [torch.as_tensor(auxiliary_info[info_index, 2:34].astype(float)).float().contiguous(), torch.as_tensor(auxiliary_info[info_index, 34:].astype(float)).float().contiguous()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_source = Path('data/cma/imgs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img_0 = Path('data/cma_small/imgs/')\n",
    "dir_mask_0 = Path('data/cma_small/masks/')\n",
    "dir_checkpoint = Path('checkpoints/')\n",
    "\n",
    "dir_img = Path('data/cma_small/imgs(2)/')\n",
    "dir_mask = Path('data/cma_small/masks(2)/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dir_img):\n",
    "    os.makedirs(dir_img)\n",
    "if not os.path.exists(os.path.join(dir_img, 'sup')):\n",
    "    os.makedirs(os.path.join(dir_img, 'sup'))\n",
    "if not os.path.exists(dir_mask):\n",
    "    os.makedirs(dir_mask)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### only filter the training dataset\n",
    "\n",
    "file_target_map = open('targeted_map_validation.csv', 'r')\n",
    "data_target_map = list(csv.reader(file_target_map, delimiter=','))\n",
    "file_target_map.close()\n",
    "\n",
    "print(len(data_target_map))\n",
    "print(data_target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filtering_new_dataset == True:\n",
    "    import cv2\n",
    "    import shutil\n",
    "\n",
    "    if os.path.isfile('data/cma_small/polygon_area_record.csv') == False:\n",
    "        with open('data/cma_small/polygon_area_record.csv','w') as fd:\n",
    "            fd.write('Key_Name,Area\\n')\n",
    "            fd.close()\n",
    "\n",
    "    counter_0 = 0\n",
    "    counter_1 = 0\n",
    "    runningtime_start = datetime.now()\n",
    "\n",
    "    targeted_image_list = ([all_image for all_image in os.listdir(dir_img_0) if any(targeted_image[0] in all_image for targeted_image in data_target_map)])\n",
    "    #for filtering_training_set in os.listdir(dir_img_0):\n",
    "    for filtering_training_set in targeted_image_list:\n",
    "        filtering_training_filename = os.path.join(dir_img_0, filtering_training_set)\n",
    "        if '_sup_' in filtering_training_filename:\n",
    "            continue\n",
    "        ext = os.path.splitext(filtering_training_filename)[1]\n",
    "        if ext != '.png':\n",
    "            continue\n",
    "        filtering_training_filename2 = os.path.join(dir_mask_0, filtering_training_set.split('.')[0]+'_mask.png')\n",
    "        #print(filtering_training_filename2)\n",
    "\n",
    "        img = cv2.imread(filtering_training_filename2)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        counter_0 = counter_0 + 1\n",
    "\n",
    "        \n",
    "        if np.unique(img).shape[0] == 2:\n",
    "            if (img > 1).any():\n",
    "                img = img / 255.0\n",
    "            this_area = np.mean(img)\n",
    "            if this_area * 255.0 > 255.0 * filtering_threshold:\n",
    "                filtered_training_filename = os.path.join(dir_img, filtering_training_set)\n",
    "                filtered_training_filename2 = os.path.join(dir_mask, filtering_training_set.split('.')[0]+'_mask.png')\n",
    "                shutil.copyfile(filtering_training_filename, filtered_training_filename)\n",
    "                shutil.copyfile(filtering_training_filename2, filtered_training_filename2)\n",
    "\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_0.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_0.png'))\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_1.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_1.png'))\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_2.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_2.png'))\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_3.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_3.png'))\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_4.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_4.png'))\n",
    "                shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_5.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_5.png'))\n",
    "\n",
    "                counter_1 = counter_1 +1\n",
    "\n",
    "            with open('data/cma_small/polygon_area_record.csv','a') as fd:\n",
    "                fd.write(str(filtering_training_set.split('.')[0])+','+str(this_area)+'\\n')\n",
    "                fd.close()\n",
    "        else:\n",
    "            if (img > 1).any():\n",
    "                this_area = 1.0\n",
    "            else:\n",
    "                this_area = 0.0\n",
    "            with open('data/cma_small/polygon_area_record.csv','a') as fd:\n",
    "                fd.write(str(filtering_training_set.split('.')[0])+','+str(this_area)+'\\n')\n",
    "                fd.close()\n",
    "        \n",
    "        '''\n",
    "        filtered_training_filename = os.path.join(dir_img, filtering_training_set)\n",
    "        filtered_training_filename2 = os.path.join(dir_mask, filtering_training_set.split('.')[0]+'_mask.png')\n",
    "        shutil.copyfile(filtering_training_filename, filtered_training_filename)\n",
    "        shutil.copyfile(filtering_training_filename2, filtered_training_filename2)\n",
    "\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_0.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_0.png'))\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_1.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_1.png'))\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_2.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_2.png'))\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_3.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_3.png'))\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_4.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_4.png'))\n",
    "        shutil.copyfile(os.path.join(dir_img_0, 'sup', filtering_training_set.split('.')[0]+'_sup_5.png'), os.path.join(dir_img, 'sup', filtering_training_set.split('.')[0]+'_sup_5.png'))\n",
    "\n",
    "        counter_1 = counter_1 +1\n",
    "        '''\n",
    "\n",
    "        if counter_0 % 5000 == 0:\n",
    "            #print('filtering training dataset: (', str(counter_0), ' / ', str(len(os.listdir(dir_img_0))-1), ')... ', datetime.now()-runningtime_start)\n",
    "            print('filtering training dataset: (', str(counter_0), ' / ', str(len(targeted_image_list)), ')... ', datetime.now()-runningtime_start)\n",
    "        \n",
    "\n",
    "    print(str(counter_1) + ' / ' + str(counter_0))\n",
    "else:\n",
    "    print('training dataset is already filtered...')\n",
    "\n",
    "# 22m 45.2s\n",
    "# 693 / 80511\n",
    "\n",
    "# 9m 12.0s\n",
    "# 283 / 33141"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split training/ validation/ testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reading_predefined_testing == False:\n",
    "    target_map_list = []\n",
    "    '''\n",
    "    with open('E:/Research/LOAM/targeted_map.csv','r') as target_map_file:\n",
    "        data_iter = csv.reader(target_map_file, delimiter = ',', quotechar = '\"')\n",
    "        target_map_list = [data for data in data_iter]\n",
    "    '''\n",
    "\n",
    "    \n",
    "    temp_test_map_name = ''\n",
    "    for testing_input in os.listdir(dir_img):\n",
    "        testing_name = os.fsdecode(testing_input)\n",
    "        if '_sup_' in testing_name:\n",
    "            continue\n",
    "        ext = os.path.splitext(testing_input)[1]\n",
    "        if ext != '.png':\n",
    "            continue\n",
    "\n",
    "        this_map_name = '_'.join(os.path.splitext(testing_input)[0].split('_')[:-4])\n",
    "        if this_map_name != temp_test_map_name:\n",
    "            # further check whether all sub-strings start with a capital letter\n",
    "            this_map_name_split = os.path.splitext(this_map_name)[0].split('_')\n",
    "            this_map_name_check = this_map_name_split[0]\n",
    "            for sub_string in this_map_name_split[1:]:\n",
    "                if sub_string[0].isupper():\n",
    "                    this_map_name_check = this_map_name_check + '_' + sub_string\n",
    "            this_map_name = this_map_name_check\n",
    "\n",
    "            if this_map_name != temp_test_map_name:\n",
    "                target_map_list.append(this_map_name)\n",
    "                print(this_map_name)\n",
    "        temp_test_map_name = this_map_name\n",
    "    target_map_list = np.asarray(target_map_list).flatten()\n",
    "\n",
    "\n",
    "    print('')\n",
    "    print(target_map_list.shape[0])\n",
    "    print(target_map_list)\n",
    "else:\n",
    "    print('Since we have the testing dataset, k-fold validation is no longer used...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reading_predefined_testing == False:\n",
    "    folded_count = target_map_list.shape[0] / k_fold_testing\n",
    "    np.random.shuffle(target_map_list)\n",
    "\n",
    "    batch_map = []\n",
    "    training_map = np.empty((k_fold_testing), dtype=object)\n",
    "    validating_map = np.empty((k_fold_testing), dtype=object)\n",
    "    testing_map = np.empty((k_fold_testing), dtype=object)\n",
    "\n",
    "    print('****** Performing '+str(k_fold_testing)+'-Fold Testing ('+str(k_fold_testing)+' Batches for '+str(target_map_list.shape[0])+' Maps) ******')\n",
    "    for kb in range(0, k_fold_testing):\n",
    "        #print(int(folded_count*k), int(folded_count*(k+1)))\n",
    "        batch_map.append(target_map_list[int(folded_count*kb): int(folded_count*(kb+1))])\n",
    "        print(batch_map[kb])\n",
    "\n",
    "    with open('output/batch_map.csv', 'w', newline=\"\") as fd:\n",
    "        writer = csv.writer(fd)\n",
    "        writer.writerows(batch_map)\n",
    "\n",
    "    for k in range(0, k_fold_testing):\n",
    "        candidate_batch = list(range(0, k_fold_testing))\n",
    "        \n",
    "        this_testing_map = k\n",
    "        candidate_batch.remove(this_testing_map)\n",
    "\n",
    "        if separate_validating_set == True:\n",
    "            this_validating_map = k+1\n",
    "            if this_validating_map >= k_fold_testing:\n",
    "                this_validating_map = this_validating_map - k_fold_testing\n",
    "            candidate_batch.remove(this_validating_map)\n",
    "\n",
    "        this_training_map_batch = []\n",
    "        for extended_training_map_batch in candidate_batch:\n",
    "            this_training_map_batch.extend(batch_map[extended_training_map_batch])\n",
    "\n",
    "        training_map[k] = np.asarray(this_training_map_batch)\n",
    "        if separate_validating_set == True:\n",
    "            validating_map[k] = np.asarray(batch_map[this_validating_map])\n",
    "        testing_map[k] = np.asarray(batch_map[this_testing_map])    \n",
    "\n",
    "    for k in range(0, k_fold_testing):\n",
    "        print('')\n",
    "        print('================== Maps for Training (' + str(training_map[k].shape[0]) + 'Maps) ('+str(k)+' Fold) ==================')\n",
    "        print(training_map[k])\n",
    "        if separate_validating_set == True:\n",
    "            print('================== Maps for Validating (' + str(validating_map[k].shape[0]) + 'Maps) ('+str(k)+' Fold) ==================')\n",
    "            print(validating_map[k])\n",
    "        print('================== Maps for Testing (' + str(testing_map[k].shape[0]) + 'Maps) ('+str(k)+' Fold) ==================')\n",
    "        print(testing_map[k])\n",
    "else:\n",
    "    print('Since we have the testing dataset, k-fold validation is no longer used...')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read pre-defined training/testing maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reading_predefined_testing == True:\n",
    "    file_target_map = open('targeted_map_validation.csv', 'r')\n",
    "    data_target_map_0 = list(csv.reader(file_target_map, delimiter=','))\n",
    "    file_target_map.close()\n",
    "\n",
    "    file_target_map = open('targeted_map_testing.csv', 'r')\n",
    "    data_target_map_1 = list(csv.reader(file_target_map, delimiter=','))\n",
    "    file_target_map.close()\n",
    "\n",
    "    training_map = np.empty((k_fold_testing), dtype=object)\n",
    "    validating_map = np.empty((k_fold_testing), dtype=object)\n",
    "    testing_map = np.empty((k_fold_testing), dtype=object)\n",
    "\n",
    "    #for k in range(0, k_fold_testing):\n",
    "    for k in range(0, 1):\n",
    "        this_training_map_batch = []\n",
    "        for targeted_map in data_target_map_0:\n",
    "            if 'MA_Grafton' in targeted_map:\n",
    "                continue\n",
    "            this_training_map_batch.extend(targeted_map)\n",
    "        training_map[k] = np.asarray(this_training_map_batch)\n",
    "\n",
    "    folded_count = len(data_target_map_1) / k_fold_testing\n",
    "    for k in range(0, k_fold_testing):\n",
    "        this_testing_map_batch = []\n",
    "        for targeted_map in range(int(k*folded_count), int((k+1)*folded_count)):\n",
    "            this_testing_map_batch.extend(data_target_map_1[targeted_map])\n",
    "        testing_map[k] = np.asarray(this_testing_map_batch)\n",
    "\n",
    "    k = 0\n",
    "    print('================== Maps for Training (' + str(training_map[k].shape[0]) + 'Maps) ('+str(k)+' Fold) ==================')\n",
    "    print(training_map[k])\n",
    "    print('')\n",
    "    for k in range(0, k_fold_testing):\n",
    "        print('================== Maps for Testing (' + str(testing_map[k].shape[0]) + 'Maps) ('+str(k)+' Fold) ==================')\n",
    "        print(testing_map[k])\n",
    "else:\n",
    "    print('Using the k-fold validation for testing...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup training information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img_testing = Path('data/cma_small/imgs/')\n",
    "dir_mask_testing = Path('data/cma_small/masks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        model,\n",
    "        device,\n",
    "        epochs: int = 10,\n",
    "        batch_size: int = 1,\n",
    "        learning_rate: float = 1e-5, # 1e-5\n",
    "        val_percent: float = 0.3, # 0.25\n",
    "        save_checkpoint: bool = True,\n",
    "        img_scale: float = 1.0,\n",
    "        amp: bool = False,\n",
    "        weight_decay: float = 1e-8,\n",
    "        momentum: float = 0.999, # 0.995\n",
    "        gradient_clipping: float = 1.0,\n",
    "        pre_defined_val: bool = False,\n",
    "        this_training_map: np = None,\n",
    "        this_validating_map: np = None,\n",
    "        auxiliary_dict: dict = None,\n",
    "):\n",
    "    print('check dictionary integrity:', len(auxiliary_dict))\n",
    "\n",
    "    if pre_defined_val == False:\n",
    "        # 1. Create dataset\n",
    "        try:\n",
    "            dataset = CarvanaDataset(dir_img, dir_mask, this_training_map, auxiliary_dict, img_scale)\n",
    "        except (AssertionError, RuntimeError, IndexError):\n",
    "            dataset = BasicDataset(dir_img, dir_mask, this_training_map, auxiliary_dict, img_scale)\n",
    "\n",
    "        # 2. Split into train / validation partitions\n",
    "        n_val = int(len(dataset) * val_percent)\n",
    "        n_train = len(dataset) - n_val\n",
    "        train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "    elif pre_defined_val == True:\n",
    "        try:\n",
    "            train_set = CarvanaDataset(dir_img, dir_mask, this_training_map, auxiliary_dict, img_scale)\n",
    "            val_set = CarvanaDataset(dir_img, dir_mask, this_validating_map, auxiliary_dict, img_scale)\n",
    "        except (AssertionError, RuntimeError, IndexError):\n",
    "            train_set = BasicDataset(dir_img, dir_mask, this_training_map, auxiliary_dict, img_scale)\n",
    "            val_set = BasicDataset(dir_img, dir_mask, this_validating_map, auxiliary_dict, img_scale)\n",
    "        dataset = train_set + val_set # merge two sub-datasets\n",
    "        n_train = len(train_set)\n",
    "        n_val = len(val_set)\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment.config.update(\n",
    "        dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "             val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
    "    )\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay, momentum=momentum, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=5)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    #criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
    "    criterion = losses.FocalLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # Set up early stopping\n",
    "    last_loss = 0\n",
    "    patience = 2\n",
    "    trigger_times = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images, true_masks, auxiliary_info_1, auxiliary_info_2 = batch['image'], batch['mask'], batch['auxiliary_1'], batch['auxiliary_2']\n",
    "\n",
    "                assert images.shape[1] == model.n_channels, \\\n",
    "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "                auxiliary_info_1 = auxiliary_info_1.to(device=device, dtype=torch.float32)\n",
    "                auxiliary_info_2 = auxiliary_info_2.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
    "                    masks_pred = model(images, auxiliary_info_1, auxiliary_info_2)\n",
    "                    if model.n_classes == 1:\n",
    "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
    "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
    "                    else:\n",
    "                        loss = criterion(masks_pred, true_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (5 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in model.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            if not torch.isinf(value).any():\n",
    "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            if not torch.isinf(value.grad).any():\n",
    "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        val_score = evaluate(model, val_loader, device, amp)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        try:\n",
    "                            experiment.log({\n",
    "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                                'validation Dice': val_score,\n",
    "                                'images': wandb.Image(images[0].cpu()),\n",
    "                                'masks': {\n",
    "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                    'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
    "                                },\n",
    "                                'step': global_step,\n",
    "                                'epoch': epoch,\n",
    "                                **histograms\n",
    "                            })\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            state_dict = model.state_dict()\n",
    "            state_dict['mask_values'] = dataset.mask_values\n",
    "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "        \n",
    "        # Check for early stopping\n",
    "        current_loss = evaluate(model, val_loader, device, amp) # range=[0, 1], to be maximized\n",
    "        print('Current Loss: ', current_loss)\n",
    "        if current_loss < last_loss:\n",
    "            trigger_times += 1\n",
    "            print('Trigger Times: ', trigger_times)\n",
    "            if trigger_times > patience:\n",
    "                print('Early Stopping...')\n",
    "                break\n",
    "        else:\n",
    "            trigger_times = 0\n",
    "            print('Trigger Times: ', trigger_times)\n",
    "\n",
    "        last_loss = current_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup predicting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_img(img_path, sup_0, sup_1, sup_2, sup_3, sup_4, sup_5, scale_factor):\n",
    "    img = Image.open(img_path)\n",
    "    img_sup_0 = Image.open(sup_0)\n",
    "    img_sup_1 = Image.open(sup_1)\n",
    "    img_sup_2 = Image.open(sup_2)\n",
    "    img_sup_3 = Image.open(sup_3)\n",
    "    img_sup_4 = Image.open(sup_4)\n",
    "    img_sup_5 = Image.open(sup_5)\n",
    "\n",
    "    img = BasicDataset.preprocess(None, img, scale_factor, is_mask=False)\n",
    "    img_sup_0 = BasicDataset.preprocess(None, img_sup_0, scale_factor, is_mask=False)\n",
    "    img_sup_1 = BasicDataset.preprocess(None, img_sup_1, scale_factor, is_mask=False)\n",
    "    img_sup_2 = BasicDataset.preprocess(None, img_sup_2, scale_factor, is_mask=False)\n",
    "    img_sup_3 = BasicDataset.preprocess(None, img_sup_3, scale_factor, is_mask=False)\n",
    "    img_sup_4 = BasicDataset.preprocess(None, img_sup_4, scale_factor, is_mask=False)\n",
    "    img_sup_5 = BasicDataset.preprocess(None, img_sup_5, scale_factor, is_mask=False)\n",
    "    \n",
    "    img_combined = np.zeros((7, img.shape[1], img.shape[2]), dtype=float)\n",
    "    img_combined[0] = img\n",
    "    img_combined[1] = img_sup_0\n",
    "    img_combined[2] = img_sup_1\n",
    "    img_combined[3] = img_sup_2\n",
    "    img_combined[4] = img_sup_3\n",
    "    img_combined[5] = img_sup_4\n",
    "    img_combined[6] = img_sup_5\n",
    "    \n",
    "    img_combined = img_combined.astype(float)\n",
    "\n",
    "    return img_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,\n",
    "                full_img,\n",
    "                targeted_auxiliary_info,\n",
    "                device,\n",
    "                scale_factor=1.0,\n",
    "                out_threshold=0.5,\n",
    "):\n",
    "    net.eval()\n",
    "    #img = torch.from_numpy(BasicDataset.preprocess(None, full_img, scale_factor, is_mask=False))\n",
    "    #img = torch.from_numpy(full_img)\n",
    "    img = torch.as_tensor(full_img.copy()).float().contiguous()\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "    #img = img.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "\n",
    "    auxiliary_info_1 = targeted_auxiliary_info[0]\n",
    "    auxiliary_info_1 = auxiliary_info_1.unsqueeze(0)\n",
    "    auxiliary_info_1 = auxiliary_info_1.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    auxiliary_info_2 = targeted_auxiliary_info[1]\n",
    "    auxiliary_info_2 = auxiliary_info_2.unsqueeze(0)\n",
    "    auxiliary_info_2 = auxiliary_info_2.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img, auxiliary_info_1, auxiliary_info_2).cpu()\n",
    "        #output = F.interpolate(output, (full_img.size[1], full_img.size[0]), mode='bilinear')\n",
    "        output = F.interpolate(output, (full_img.shape[2], full_img.shape[1]), mode='bilinear')\n",
    "        if net.n_classes > 1:\n",
    "            mask = output.argmax(dim=1)\n",
    "        else:\n",
    "            mask = torch.sigmoid(output) > out_threshold\n",
    "\n",
    "    return mask[0].long().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        return f'{os.path.splitext(fn)[0]}_OUT.png'\n",
    "\n",
    "    return args['output'] or list(map(_generate_name, args['input']))\n",
    "\n",
    "\n",
    "def mask_to_image(mask: np.ndarray, mask_values):\n",
    "    if isinstance(mask_values[0], list):\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)\n",
    "    elif mask_values == [0, 1]:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)\n",
    "    else:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "\n",
    "    for i, v in enumerate(mask_values):\n",
    "        out[mask == i] = v\n",
    "\n",
    "    return Image.fromarray(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "from loam.loam_model import LOAM\n",
    "\n",
    "temp_model = LOAM(n_channels=7, n_classes=2, bilinear=False)\n",
    "summary(temp_model, input_size=[(1,7,1024,1024), (1,32), (1,9)])\n",
    "\n",
    "# print(LOAM(n_channels=4, n_classes=2, bilinear=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if training_needed == True:\n",
    "    #for k in range(0, k_fold_testing):\n",
    "    k = 0\n",
    "\n",
    "    print('')\n",
    "    print('================== Perform '+str(k_fold_testing)+'-Fold Testing (' + str(k) + ' Fold) ==================')\n",
    "\n",
    "    runningtime_start_global = datetime.now()\n",
    "    #dir_checkpoint = Path('checkpoints/fold_'+str(k)+'/')\n",
    "    dir_checkpoint = Path('checkpoints/fold_0/')\n",
    "\n",
    "    ''' Setup training arguments '''\n",
    "    args = {\n",
    "        \"epochs\": 20,\n",
    "        \"batch-size\": 1,\n",
    "        \"learning-rate\": 1e-5,\n",
    "        \"load\": False, # load model from a .pth file\n",
    "        \"scale\": 1.0, # downscaling factor of the images\n",
    "        \"validation\": 20, # percentage (0-100)\n",
    "        \"amp\": True, # mixed precision\n",
    "        \"bilinear\": False, # bilinear upsampling\n",
    "        \"classes\": 2 # number of classes\n",
    "    }\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    model = LOAM(n_channels=7, n_classes=args['classes'], bilinear=args['bilinear'])\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "    logging.info(f'Network:\\n'\n",
    "                    f'\\t{model.n_channels} input channels\\n'\n",
    "                    f'\\t{model.n_classes} output channels (classes)\\n'\n",
    "                    f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "\n",
    "    ''' Perform training '''\n",
    "    if args['load']:\n",
    "        state_dict = torch.load(args['load'], map_location=device)\n",
    "        del state_dict['mask_values']\n",
    "        model.load_state_dict(state_dict)\n",
    "        logging.info(f'Model loaded from {str(args[\"load\"])}')\n",
    "\n",
    "    model.to(device=device)\n",
    "    try:\n",
    "        train_model(\n",
    "            model=model,\n",
    "            epochs=args['epochs'],\n",
    "            batch_size=args['batch-size'],\n",
    "            learning_rate=args['learning-rate'],\n",
    "            device=device,\n",
    "            img_scale=args['scale'],\n",
    "            val_percent=args['validation'] / 100,\n",
    "            amp=args['amp'],\n",
    "            pre_defined_val=separate_validating_set,\n",
    "            this_training_map=training_map[k],\n",
    "            this_validating_map=validating_map[k],\n",
    "            auxiliary_dict = auxiliary_dict_indexed\n",
    "        )\n",
    "    except torch.cuda.OutOfMemoryError:\n",
    "        logging.error('Detected OutOfMemoryError! '\n",
    "                        'Enabling checkpointing to reduce memory usage, but this slows down training. '\n",
    "                        'Consider enabling AMP (--amp) for fast and memory efficient training')\n",
    "        torch.cuda.empty_cache()\n",
    "        model.use_checkpointing()\n",
    "        train_model(\n",
    "            model=model,\n",
    "            epochs=args['epochs'],\n",
    "            batch_size=args['batch-size'],\n",
    "            learning_rate=args['learning-rate'],\n",
    "            device=device,\n",
    "            img_scale=args['scale'],\n",
    "            val_percent=args['validation'] / 100,\n",
    "            amp=args['amp'],\n",
    "            pre_defined_val=separate_validating_set,\n",
    "            this_training_map=training_map[k],\n",
    "            this_validating_map=validating_map[k],\n",
    "            auxiliary_dict = auxiliary_dict_indexed\n",
    "        )\n",
    "\n",
    "    print('time_checkpoint (model training): ', datetime.now()-runningtime_start_global)\n",
    "else:\n",
    "    print('training is already done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_epoch_found = False\n",
    "targeted_epoch = -1\n",
    "dir_checkpoint = Path('checkpoints/fold_0/')\n",
    "\n",
    "for epoch_id in range(14, 0, -1):\n",
    "    if os.path.isfile(os.path.join(dir_checkpoint, 'checkpoint_epoch'+str(epoch_id)+'.pth')):\n",
    "        targeted_epoch_found = True\n",
    "        targeted_epoch = epoch_id\n",
    "        break\n",
    "\n",
    "if targeted_epoch_found == False:\n",
    "    print('No epoch for a successfully trained model is found...')\n",
    "else:\n",
    "    epoch_id_mod = epoch_id# - 2\n",
    "    if os.path.isfile(os.path.join(dir_checkpoint, 'checkpoint_epoch'+str(epoch_id_mod)+'.pth')):\n",
    "        targeted_epoch = epoch_id_mod\n",
    "    print('Selecting epoch '+str(targeted_epoch)+' for testing...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runningtime_start_global = datetime.now()\n",
    "\n",
    "for k in range(0, k_fold_testing):\n",
    "\n",
    "    ''' Setup predicting arguments '''\n",
    "    dir_pred_testing = Path('predict/fold_'+str(k)+'/cma_small/predict/')\n",
    "    dir_pred_testing1 = Path('predict/fold_'+str(k)+'/cma/predict/')\n",
    "    #dir_pred_testing = Path('predict/fold_0/cma_small/predict/')\n",
    "    #dir_pred_testing1 = Path('predict/fold_0/cma/predict/')\n",
    "\n",
    "    if not os.path.exists(dir_pred_testing):\n",
    "        os.makedirs(dir_pred_testing)\n",
    "    if not os.path.exists(dir_pred_testing1):\n",
    "        os.makedirs(dir_pred_testing1)\n",
    "\n",
    "    args = {\n",
    "        \"model\": os.path.join(dir_checkpoint, 'checkpoint_epoch'+str(targeted_epoch)+'.pth'),\n",
    "        \"input\": dir_img_testing, # Filenames of input images\n",
    "        \"output\": dir_pred_testing, # Filenames of output images\n",
    "        \"output_merged\": dir_pred_testing1, # Filenames of output images (merged)\n",
    "        \"viz\": False,\n",
    "        \"no-save\": False,\n",
    "        \"mask-threshold\": 0.1, # Minimum probability value to consider a mask pixel white\n",
    "        \"scale\": 1.0, # Scale factor for the input images\n",
    "        \"amp\": True, # mixed precision\n",
    "        \"bilinear\": False, # bilinear upsampling\n",
    "        \"classes\": 2 # number of classes\n",
    "    }\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "    net = LOAM(n_channels=7, n_classes=args['classes'], bilinear=args['bilinear'])\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Loading model {args[\"model\"]}')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    state_dict = torch.load(args['model'], map_location=device)\n",
    "    mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    logging.info('Model loaded!')\n",
    "\n",
    "\n",
    "    ''' Check predicting information '''\n",
    "    #testing_key = [os.path.splitext(file)[0] for file in os.listdir(args['input']) if os.path.isfile(os.path.join(args['input'], file)) and not file.startswith('.') and (('_'.join(os.path.splitext(file)[0].split('_')[:-4])) in testing_map[k])]\n",
    "    testing_key = [os.path.splitext(file)[0] for file in os.listdir(args['input']) if os.path.isfile(os.path.join(args['input'], file)) and not file.startswith('.') and any(testing_map_name in file for testing_map_name in testing_map[k])]\n",
    "    \n",
    "    testing_key_count = len(testing_key)\n",
    "    print(str(testing_key_count)+'images to be predicted... ')\n",
    "\n",
    "\n",
    "    ''' Perform predicting '''\n",
    "    candidate_to_merge = []\n",
    "\n",
    "    predict_counter = 0\n",
    "    runningtime_start = datetime.now()\n",
    "\n",
    "    with tqdm(total=testing_key_count, desc=f'Prediction - Fold {(k+1)}/{k_fold_testing}', unit='img') as pbar0:\n",
    "        for testing_input in os.listdir(args['input']):\n",
    "            testing_name = os.fsdecode(testing_input)\n",
    "            if '_sup_' in testing_name:\n",
    "                continue\n",
    "            ext = os.path.splitext(testing_input)[1]\n",
    "            if ext != '.png':\n",
    "                continue\n",
    "\n",
    "            #this_map_name = '_'.join(os.path.splitext(testing_input)[0].split('_')[:-4])\n",
    "            #if this_map_name in testing_map[k]:\n",
    "            if any(testing_map_name in testing_input for testing_map_name in testing_map[k]):\n",
    "                # print('get testing map...')\n",
    "                testing_input_filename = os.path.join(args['input'], testing_input)\n",
    "                testing_output_filename = os.path.join(args['output'], testing_name.split('.')[0]+'_predict.png')\n",
    "\n",
    "                # logging.info(f'Predicting image {testing_input_filename} ...')\n",
    "                img = Image.open(testing_input_filename)\n",
    "                img_path = testing_input_filename\n",
    "\n",
    "                img_sup_0 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_0.png')\n",
    "                img_sup_1 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_1.png')\n",
    "                img_sup_2 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_2.png')\n",
    "                img_sup_3 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_3.png')\n",
    "                img_sup_4 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_4.png')\n",
    "                img_sup_5 = os.path.join(args['input'], 'sup', testing_input.split('.')[0]+'_sup_5.png')\n",
    "\n",
    "                image_key_name = str('_'.join((testing_input.split('.')[0]).split('_')[:-2]))\n",
    "                #print(image_key_name)\n",
    "                targeted_auxi = auxiliary_dict_indexed[image_key_name]\n",
    "\n",
    "                mask = predict_img(net=net,\n",
    "                                    full_img=combine_img(img_path, img_sup_0, img_sup_1, img_sup_2, img_sup_3, img_sup_4, img_sup_5, args['scale']),\n",
    "                                    targeted_auxiliary_info = targeted_auxi,\n",
    "                                    scale_factor=args['scale'],\n",
    "                                    out_threshold=args['mask-threshold'],\n",
    "                                    device=device)\n",
    "                \n",
    "                if not args['no-save']:\n",
    "                    out_filename = testing_output_filename\n",
    "                    result = mask_to_image(mask, mask_values)\n",
    "                    result.save(out_filename)\n",
    "                    # logging.info(f'Mask saved to {out_filename}')\n",
    "\n",
    "                    if 'poly_0_0.png' in testing_name:\n",
    "                        this_map_name_index = -4\n",
    "                        this_map_name = ''\n",
    "                        this_legend_name = ''\n",
    "                        for index_attemp in range(-4, -testing_input.count('_')-1, -1):\n",
    "                            this_map_name_candidate = '_'.join(os.path.splitext(testing_input)[0].split('_')[:index_attemp])\n",
    "                            if this_map_name_candidate in testing_map[k]:\n",
    "                                this_map_name = this_map_name_candidate\n",
    "                                this_legend_name = '_'.join(os.path.splitext(testing_input)[0].split('_')[index_attemp:-2])\n",
    "                                break\n",
    "                        #if this_map_name != temp_name_set[0] or this_legend_name != temp_name_set[1]:\n",
    "                            #print(this_map_name, this_legend_name)\n",
    "                            #temp_name_set = [this_map_name, this_legend_name]\n",
    "                            #name_set_counting += 1\n",
    "\n",
    "                        map_name = this_map_name\n",
    "                        label_name = this_legend_name\n",
    "                        candidate_to_merge.append([map_name, label_name])\n",
    "                \n",
    "                        #map_name = '_'.join(testing_name.split('_')[:-4])\n",
    "                        #label_name = testing_name.split('_')[-4]\n",
    "                        #candidate_to_merge.append([map_name, label_name])\n",
    "\n",
    "                if args['viz']:\n",
    "                    # logging.info(f'Visualizing results for image {testing_name}, close to continue...')\n",
    "                    plot_img_and_mask(img, mask)\n",
    "                \n",
    "                predict_counter = predict_counter + 1\n",
    "                if predict_counter % 2500 == 0:\n",
    "                    print('Making predictions... ('+str(predict_counter)+' / '+str(testing_key_count)+')... ', datetime.now()-runningtime_start)\n",
    "                pbar0.update(1)\n",
    "\n",
    "\n",
    "    ''' Merge back to complete image '''\n",
    "    print(str(len(candidate_to_merge))+' images to be merged... ')\n",
    "\n",
    "    with tqdm(total=len(candidate_to_merge), desc=f'Merge - Fold {(k+1)}/{k_fold_testing}', unit='img') as pbar0:\n",
    "        for map_name, label_name in candidate_to_merge:\n",
    "            source_name = map_name + '_' + label_name + '.png'\n",
    "            source_filename = os.path.join(dir_source, source_name)\n",
    "\n",
    "            img = cv2.imread(source_filename)\n",
    "            # original_shape = img.shape\n",
    "            # print(source_filename, original_shape[0:2])\n",
    "            empty_grid = np.zeros((img.shape[0], img.shape[1]), dtype='uint8').astype(float)\n",
    "            empty_flag = True\n",
    "\n",
    "            for r in range(0,math.ceil(img.shape[0]/1024)):\n",
    "                for c in range(0,math.ceil(img.shape[1]/1024)):\n",
    "                    this_block_source = os.path.join(args['output'], str(source_name.split('.')[0]+\"_\"+str(r)+\"_\"+str(c)+\"_predict.png\"))\n",
    "                    #print(this_block_source)\n",
    "                    already_predicted = os.path.isfile(this_block_source)\n",
    "\n",
    "                    if already_predicted == True:\n",
    "                        block_img = cv2.imread(this_block_source)\n",
    "                        block_img = cv2.cvtColor(block_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        r_0 = r*1024\n",
    "                        r_1 = min(r*1024+1024, img.shape[0])\n",
    "                        c_0 = c*1024\n",
    "                        c_1 = min(c*1024+1024, img.shape[1])\n",
    "                        \n",
    "                        empty_grid[r_0:r_1, c_0:c_1] = block_img[r_0%1024:(r_1-r_0), c_0%1024:(c_1-c_0)]\n",
    "                    else:\n",
    "                        empty_flag = False\n",
    "                        break\n",
    "                if empty_flag == False:\n",
    "                    break\n",
    "            \n",
    "            if empty_flag == True:\n",
    "                cv2.imwrite(os.path.join(args['output_merged'], str(source_name.split('.')[0]+\"_predict.png\")), empty_grid)\n",
    "                #logging.info(f'Merging predicted image {source_name} ...')\n",
    "                pbar0.update(1)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "    ''' Conduct performance evaluation '''\n",
    "    '''\n",
    "    print(str(len(os.listdir(args['output_merged'])))+' images to be evaluated with groundtruth... ')\n",
    "\n",
    "    info_set = []\n",
    "    for prediction_merged in os.listdir(args['output_merged']):\n",
    "        prediction_name = os.fsdecode(prediction_merged)\n",
    "        prediction_filename = os.path.join(args['output_merged'], prediction_name)\n",
    "\n",
    "        map_name = '_'.join(prediction_name.split('_')[:-3])\n",
    "        label_name = prediction_name.split('_')[-3]\n",
    "\n",
    "        map_filename = os.path.join('H:/Research/LOAM/Data/testing', map_name+str('.tif')) # Path to the input dataset\n",
    "        label_filename = map_filename.replace('.tif','.json')\n",
    "        groundtruth_filename = os.path.join('E:/Research/LOAM/Data/testing_groundtruth', map_name+'_'+label_name+str('.tif')) # Path to the corresponding groundtruth dataset\n",
    "        if os.path.isfile(groundtruth_filename) == False:\n",
    "            print('no groundturht provided... ', groundtruth_filename)\n",
    "            continue\n",
    "\n",
    "        prediction_source_filename = os.path.join('H:/Research/LOAM/LOAM/data/cma/imgs', map_name+'_'+label_name+str('.png')) # Path to the output\n",
    "\n",
    "        info_set_placeholder = []\n",
    "        info_set_placeholder.append(map_filename)\n",
    "        info_set_placeholder.append(label_filename)\n",
    "        info_set_placeholder.append(prediction_filename)\n",
    "        info_set_placeholder.append(groundtruth_filename)\n",
    "        info_set_placeholder.append(map_name)\n",
    "        info_set_placeholder.append(label_name)\n",
    "\n",
    "        info_set_placeholder.append(prediction_source_filename)\n",
    "        # print(info_set_placeholder)\n",
    "        info_set.append(info_set_placeholder)\n",
    "\n",
    "\n",
    "    #runningtime_start=datetime.now()\n",
    "    performance_block = []\n",
    "\n",
    "    if os.path.isfile('output/performance_folded.csv') == False:\n",
    "        with open('output/performance_folded.csv','w') as fd:\n",
    "            fd.write('Fold,Map_Name,Key_Name,Pre-Precision,Pre-Recall,Pre-F1_Score,Post-Precision,Post-Recall,Post-F1_Score\\n')\n",
    "            fd.close()\n",
    "\n",
    "    with tqdm(total=len(info_set), desc=f'Evaluation - Fold {(k+1)}/{k_fold_testing}', unit='img') as pbar0:\n",
    "        for batch in range(0, math.ceil(len(info_set)/PROCESSES)):\n",
    "            batch_range = [PROCESSES*batch, min(PROCESSES*(batch+1), len(info_set))]\n",
    "            #print(batch_range)\n",
    "\n",
    "            with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                #multiprocessing_results = [pool.apply_async(validation_evaluation_worker, (info_id,info_set[info_id],)) for info_id in range(0, len(info_set))]\n",
    "                callback = pool.starmap_async(validation_evaluation_worker.validation_evaluation_worker, [(info_id, info_set[info_id], ) for info_id in range(batch_range[0], batch_range[1])]) # len(info_set)\n",
    "                multiprocessing_results  = callback.get()\n",
    "                    \n",
    "                for returned_info in multiprocessing_results:\n",
    "                    #map_name, legend_name, precision, recall, f_score = returned_info\n",
    "                    try:\n",
    "                        returned = returned_info\n",
    "                        map_name = returned[0]\n",
    "                        legend_name = returned[1]\n",
    "                        precision_0 = returned[2]\n",
    "                        recall_0 = returned[3]\n",
    "                        f_score_0 = returned[4]\n",
    "                        precision_1 = returned[5]\n",
    "                        recall_1 = returned[6]\n",
    "                        f_score_1 = returned[7]\n",
    "                        print(map_name, legend_name, precision_0, recall_0, f_score_0, precision_1, recall_1, f_score_1)\n",
    "                        performance_block.append(returned)\n",
    "\n",
    "                        with open('output/performance_folded.csv','a') as fd:\n",
    "                            fd.write(str(k)+','+map_name+','+legend_name+','+str(precision_0)+','+str(recall_0)+','+str(f_score_0)+','+str(precision_1)+','+str(recall_1)+','+str(f_score_1)+'\\n')\n",
    "                            #fd.write(map_name+','+legend_name+','+str(returned[2])+','+str(returned[3])+','+str(returned[4])+','+str(returned[5])+','+str(returned[6])+','+str(returned[7])+','+str(returned[8])+','+str(returned[9])+','+str(returned[10])+','+str(returned[11])+','+str(returned[12])+','+str(returned[13])+','+str(returned[14])+','+str(returned[15])+','+str(returned[16])+','+str(returned[17])+','+str(returned[18])+','+str(returned[19])+','+str(returned[20])+','+str(returned[21])+','+str(returned[22])+'\\n')\n",
    "                            fd.close()\n",
    "                            pbar0.update(1)\n",
    "                    except:\n",
    "                        with open('output/performance_folded.csv','a') as fd:\n",
    "                            fd.write(str(k)+','+'error,error\\n')\n",
    "                            fd.close()\n",
    "                            pbar0.update(1)\n",
    "            #if batch%5 == 0:\n",
    "                #print('time_checkpoint('+str(batch)+'): ', datetime.now()-runningtime_start)\n",
    "            #print(performance_block)\n",
    "            performance_block = []\n",
    "\n",
    "    '''\n",
    "\n",
    "    \n",
    "    print('time_checkpoint (model inferring, fold- '+str(k)+'): ', datetime.now()-runningtime_start_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
