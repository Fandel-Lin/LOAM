{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import math\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy import sparse\n",
    "import pyvips\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import postprocessing_workers.postprocessing_for_bitmap_worker as postprocessing_for_bitmap_worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "print(multiprocessing.cpu_count())\n",
    "multiprocessing.set_start_method('spawn', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSES = 8\n",
    "if PROCESSES > multiprocessing.cpu_count():\n",
    "    PROCESSES = (int)(multiprocessing.cpu_count()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='Data/testing' # set path to the targeted dataset\n",
    "solution_dir='Solution_0518' # set path to metadata-preprocessing output\n",
    "data_dir_groundtruth='Data/testing_groundtruth' # set path to the groundtruth of the targeted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir_img = 'LOAM\\data\\cma\\imgs'\n",
    "target_dir_mask = 'LOAM\\data\\cma\\masks'\n",
    "\n",
    "target_dir_img_small = 'LOAM\\data\\cma_small\\imgs'\n",
    "target_dir_mask_small = 'LOAM\\data\\cma_small\\masks'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join('LOAM', 'data')):\n",
    "    os.makedirs(os.path.join('LOAM', 'data'))\n",
    "if not os.path.exists(os.path.join('LOAM', 'data', 'cma')):\n",
    "    os.makedirs(os.path.join('LOAM', 'data', 'cma'))\n",
    "if not os.path.exists(os.path.join('LOAM', 'data', 'cma_small')):\n",
    "    os.makedirs(os.path.join('LOAM', 'data', 'cma_small'))\n",
    "\n",
    "if not os.path.exists(target_dir_img):\n",
    "    os.makedirs(target_dir_img)\n",
    "    os.makedirs(os.path.join(target_dir_img, 'sup'))\n",
    "if not os.path.exists(target_dir_mask):\n",
    "    os.makedirs(target_dir_mask)\n",
    "    os.makedirs(os.path.join(target_dir_mask, 'sup'))\n",
    "if not os.path.exists(target_dir_img_small):\n",
    "    os.makedirs(target_dir_img_small)\n",
    "    os.makedirs(os.path.join(target_dir_img_small, 'sup'))\n",
    "if not os.path.exists(target_dir_mask_small):\n",
    "    os.makedirs(target_dir_mask_small)\n",
    "    os.makedirs(os.path.join(target_dir_mask_small, 'sup'))\n",
    "\n",
    "print('Set up directories in \"LOAM/data\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir='Data/validation'\n",
    "candidate_map_name_for_polygon = []\n",
    "candidate_legend_name_for_polygon = []\n",
    "total_poly_counter = 0\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        map_name = file_name.replace('.json', '')\n",
    "        #print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        \n",
    "        legend_name_placeholder = []\n",
    "        poly_counter = 0\n",
    "\n",
    "        with open(test_json) as f:\n",
    "            gj = json.load(f)\n",
    "        for this_gj in gj['shapes']:\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names and '_pt' not in names and '_line' not in names:\n",
    "                print(names)\n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            poly_counter = poly_counter+1\n",
    "            legend_name_placeholder.append(names)\n",
    "        \n",
    "        if poly_counter > 0:\n",
    "            candidate_map_name_for_polygon.append(map_name)\n",
    "            candidate_legend_name_for_polygon.append(legend_name_placeholder)\n",
    "\n",
    "            total_poly_counter = total_poly_counter + poly_counter\n",
    "            print(poly_counter, '\\t', filename)\n",
    "print(total_poly_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = 'Data/validation'\n",
    "#data_dir0 = 'validation_extraction'\n",
    "data_dir0 = solution_dir + str('/intermediate7(2)')\n",
    "data_dir1 = data_dir_groundtruth\n",
    "\n",
    "data_dir2 = solution_dir + str('/intermediate7')\n",
    "data_dir3 = solution_dir + str('/intermediate5')\n",
    "data_dir4 = solution_dir + str('/intermediate8(2)')\n",
    "\n",
    "\n",
    "info_set = []\n",
    "\n",
    "### For polygon extraction\n",
    "for map_id in range(0, len(candidate_map_name_for_polygon)):\n",
    "    runningtime_start=datetime.now()\n",
    "    grid_counter = 0\n",
    "\n",
    "\n",
    "    target_map = candidate_map_name_for_polygon[map_id]+'.tif'\n",
    "    file_map = os.path.join(data_dir, target_map)\n",
    "    file_json = os.path.join(data_dir, target_map.replace('.tif','.json'))\n",
    "    \n",
    "    legend_for_multiprocessing = []\n",
    "    for legend_id in range(0, len(candidate_legend_name_for_polygon[map_id])):\n",
    "        target_legend = candidate_map_name_for_polygon[map_id]+'_'+candidate_legend_name_for_polygon[map_id][legend_id]+\".tif\" # groundtruth\n",
    "        target_legend_v1 = candidate_map_name_for_polygon[map_id]+'/'+candidate_map_name_for_polygon[map_id]+'_'+candidate_legend_name_for_polygon[map_id][legend_id]+\"_v7.png\" # extraction\n",
    "        #target_legend_v2 = candidate_map_name_for_polygon[map_id]+'/'+candidate_map_name_for_polygon[map_id]+'_'+candidate_legend_name_for_polygon[map_id][legend_id]+\"_v2.png\"\n",
    "                    \n",
    "        file_extraction = os.path.join(data_dir0, target_legend_v1)\n",
    "        file_groundtruth = os.path.join(data_dir1, target_legend)\n",
    "        \n",
    "        if os.path.isfile(file_groundtruth) == False:\n",
    "            print('not provided... ', file_groundtruth)\n",
    "            continue\n",
    "        \n",
    "        if os.path.isfile(file_extraction) == False:\n",
    "            print('not extracted... ', file_extraction)\n",
    "            continue\n",
    "\n",
    "        legend_for_multiprocessing.append(legend_id)\n",
    "    print(map_id, len(legend_for_multiprocessing))\n",
    "    \n",
    "    \n",
    "    with multiprocessing.Pool(PROCESSES) as pool:\n",
    "        callback = pool.starmap_async(postprocessing_for_bitmap_worker.postprocessing_for_bitmap_worker_multiple_image, [(map_id, this_legend_id, candidate_map_name_for_polygon[map_id], candidate_legend_name_for_polygon[map_id][this_legend_id], data_dir0, data_dir1, data_dir2, data_dir3, data_dir4, target_dir_img, target_dir_mask, target_dir_img_small, target_dir_mask_small, ) for this_legend_id in legend_for_multiprocessing])\n",
    "        multiprocessing_results = callback.get()\n",
    "\n",
    "        for return_map_id, return_legend_id, number_of_grids in multiprocessing_results:\n",
    "            grid_counter = grid_counter + number_of_grids\n",
    "\n",
    "    runningtime_end = datetime.now()-runningtime_start\n",
    "\n",
    "    if os.path.isfile('LOAM/data/'+'running_time_record_v1.csv') == False:\n",
    "        with open('LOAM/data/'+'running_time_record_v1.csv','w') as fd:\n",
    "            fd.write('Map_Id,Map_Name,Legend_Count,RunningTime\\n')\n",
    "            fd.close()\n",
    "    if os.path.isfile('LOAM/data/'+'generated_grids_record_v1.csv') == False:\n",
    "        with open('LOAM/data/'+'generated_grids_record_v1.csv','w') as fd:\n",
    "            fd.write('Map_Id,Map_Name,Legend_Count,GeneratedGrids\\n')\n",
    "            fd.close()\n",
    "\n",
    "    with open('LOAM/data/'+'running_time_record_v1.csv','a') as fd:\n",
    "        fd.write(str(map_id)+','+candidate_map_name_for_polygon[map_id]+','+str(len(legend_for_multiprocessing))+','+str(runningtime_end)+'\\n')\n",
    "        fd.close()\n",
    "    with open('LOAM/data/'+'generated_grids_record_v1.csv','a') as fd:\n",
    "        fd.write(str(map_id)+','+candidate_map_name_for_polygon[map_id]+','+str(len(legend_for_multiprocessing))+','+str(grid_counter)+'\\n')\n",
    "        fd.close()\n",
    "\n",
    "# 59m 11.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
