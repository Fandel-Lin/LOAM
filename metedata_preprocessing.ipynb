{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from statistics import median\n",
    "import csv\n",
    "import math\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from scipy.signal import convolve2d\n",
    "from scipy.stats import beta\n",
    "import os\n",
    "from os.path import exists\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "import math\n",
    "from datetime import datetime\n",
    "from skimage.morphology import skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a949524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "#print(multiprocessing.cpu_count())\n",
    "multiprocessing.set_start_method('spawn', True)\n",
    "\n",
    "PROCESSES = 8\n",
    "if PROCESSES > multiprocessing.cpu_count():\n",
    "    PROCESSES = (int)(multiprocessing.cpu_count()/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060f374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d09eace",
   "metadata": {},
   "source": [
    "### Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a04d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_multiprocessing = True # Always set to True !!\n",
    "for_each_loop_global = PROCESSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e977b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_cropping = True # Set to True if map cropping is needed\n",
    "map_preprocessing = True  # Set to True if map preprocessing is needed\n",
    "\n",
    "generate_boundary_extraction = True # Set to True if boundary extraction is needed (viewed as one of the preprocessing step)\n",
    "generate_boundary_groundtruth = True # Set to True for one time\n",
    "\n",
    "crop_legend = True # Always set to True (remove legend area from basemap)\n",
    "preprocessing_recoloring = True # Always set to True under current setting\n",
    "printing_auxiliary_information = True # Always set to True under current setting\n",
    "\n",
    "simple_preprocessing = True # Set to True to support fast testing during development (always set to True during development)\n",
    "\n",
    "smoothing_map = False # Always set to False under current setting\n",
    "generate_text_pattern_probability = False # Always set to False under current setting\n",
    "postprocessing_floodfill = False # Set to False under current setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a36788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_intermediate_image = True # create directory and output intermediate images \n",
    "# output for cropped map => 'intermediate6/cropped_map_mask'\n",
    "# output for polygon extraction => 'intermediate7(2)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='Data/testing' # path to input maps\n",
    "data_boundary_dir='Data/testing_groundtruth' # path to groundtruth maps (only used for generating the groundtruth of boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b53f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutiona_dir='Solution_0518/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3855876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import extractor_workers.preprocessing_worker as preprocessing_worker\n",
    "import extractor_workers.cropping_worker as cropping_worker\n",
    "\n",
    "import extractor_workers.extraction_step0_color_difference_worker as extraction_step0_color_difference_worker\n",
    "import extractor_workers.extraction_step0_find_legend_in_map_worker as extraction_step0_find_legend_in_map_worker\n",
    "import extractor_workers.extraction_step1_worker as extraction_step1_worker\n",
    "import extractor_workers.extraction_step2_worker as extraction_step2_worker\n",
    "import extractor_workers.extraction_step3_worker as extraction_step3_worker\n",
    "import extractor_workers.extraction_step4_worker as extraction_step4_worker\n",
    "import extractor_workers.extraction_step5_worker as extraction_step5_worker\n",
    "import extractor_workers.extraction_step6_pre_update_worker as extraction_step6_pre_update_worker\n",
    "import extractor_workers.extraction_step6_specify_overlap_legend_worker as extraction_step6_specify_overlap_legend_worker\n",
    "import extractor_workers.extraction_step6_find_legend_in_map_worker as extraction_step6_find_legend_in_map_worker\n",
    "import extractor_workers.extraction_step6_compare_against_competitor_worker as extraction_step6_compare_against_competitor_worker\n",
    "import extractor_workers.extraction_step7_worker as extraction_step7_worker\n",
    "import extractor_workers.extraction_step8_postprocessing_worker as extraction_step8_postprocessing_worker\n",
    "\n",
    "print('extractor_workers are imported...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4088eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('========================================== Polygon Extraction Setting ==========================================')\n",
    "print('*Solution directory => \"' + solutiona_dir + '\"')\n",
    "\n",
    "print('')\n",
    "print('*Intput for polygon extraction => \"' + data_dir + '\"')\n",
    "print('*Output for polygon extraction => \"' + solutiona_dir + 'intermediate7(2)/Output\"')\n",
    "\n",
    "if print_intermediate_image == True:\n",
    "    print(' - Output for intermediate basemap => \"' + solutiona_dir + 'intermediate7\"')\n",
    "    print(' - Output for intermediate extraction => \"' + solutiona_dir + 'intermediate7(2)/(Map_Name)\"')\n",
    "    print(' - Output for cropped map => \"' + solutiona_dir + 'intermediate6/cropped_map_mask\" (Supporting point, line, polygon)')\n",
    "if generate_boundary_groundtruth == True:\n",
    "    print(' - Output for boundary groundtruth => \"' + solutiona_dir + 'intermediate5/Groundtruth\"')\n",
    "if generate_boundary_extraction == True:\n",
    "    print(' - Output for boundary extraction => \"' + solutiona_dir + 'intermediate5/Extraction\"')\n",
    "\n",
    "print('')\n",
    "print('*Adjustable (Set to \"True\" is highly recommended due to time complexity)')\n",
    "print(' - Multiprocessing => ' + str(split_multiprocessing))\n",
    "print(' - Simple preprocessing => ' + str(simple_preprocessing))\n",
    "print('')\n",
    "print('*Adjustable (Set to \"True\" for only one time to process the basemap)')\n",
    "print(' - Crop basemap => ' + str(map_cropping) + '\\t\\t\\t\\t (set to \"True\" only if one needs to crop those maps that do not have polygon features)')\n",
    "print(' - Preprocess basemap => ' + str(map_preprocessing) + '\\t\\t\\t (set to \"True\" to crop those maps that have polygon features at the same time)')\n",
    "print(' - Generate boundary groundtruth => ' + str(generate_boundary_groundtruth) + '\\t (set to \"True\" to generate boundary groundtruth)')\n",
    "#print('')\n",
    "#print('*Experimental (Set to \"True\" for experimental functionalities)')\n",
    "print(' - Extract boundaries as polygons => ' + str(generate_boundary_extraction) + '\\t (set to \"True\" to extract boundaries/ black as a polygon key)')\n",
    "print('')\n",
    "print('*Currently fixed')\n",
    "print(' - Crop legend => ' + str(crop_legend) + ' (shall be \"True\")')\n",
    "print(' - Input DTM-smoothed basemap => ' + str(smoothing_map) + ' (shall be \"False\")')\n",
    "print(' - Generate text pattern probability => ' + str(generate_text_pattern_probability) + ' (shall be \"False\")')\n",
    "\n",
    "print('')\n",
    "if split_multiprocessing == True:\n",
    "    print('*Multiprocessing with '+str(PROCESSES)+' processes...')\n",
    "\n",
    "print('================================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0899e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2126818c",
   "metadata": {},
   "source": [
    "# Below is a Preprocessing Step for All Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7107562",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists(solutiona_dir+str('intermediate6/')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate6/'))\n",
    "\n",
    "candidate_file_name_for_preprocessing = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "\n",
    "        any_counter = 0\n",
    "\n",
    "        with open(test_json) as f:\n",
    "            gj = json.load(f)\n",
    "        for this_gj in gj['shapes']:\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names and '_pt' not in names and '_line' not in names:\n",
    "                print(names)\n",
    "            any_counter = any_counter+1\n",
    "            break\n",
    "        \n",
    "        if any_counter > 0:\n",
    "            candidate_file_name_for_preprocessing.append(file_name)\n",
    "print(len(candidate_file_name_for_preprocessing))\n",
    "print(candidate_file_name_for_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b68edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if simple_preprocessing == True:\n",
    "    print('Enabling simple preprocessing...')\n",
    "    original_dataset_size = len(candidate_file_name_for_preprocessing)\n",
    "\n",
    "    file_target_map = open('targeted_map.csv', 'r')\n",
    "    data_target_map = list(csv.reader(file_target_map, delimiter=','))\n",
    "    file_target_map.close()\n",
    "\n",
    "    #print(data_target_map)\n",
    "\n",
    "    candidate_file_name_for_preprocessing_temp = candidate_file_name_for_preprocessing.copy()\n",
    "    candidate_file_name_for_preprocessing = []\n",
    "\n",
    "    for file_counter in range(0, len(candidate_file_name_for_preprocessing_temp)):\n",
    "        file_name = candidate_file_name_for_preprocessing_temp[file_counter]\n",
    "        #print(file_name.split('.')[0])\n",
    "        if any(file_name.split('.')[0] in target_map for target_map in data_target_map):\n",
    "            candidate_file_name_for_preprocessing.append(file_name)\n",
    "\n",
    "    print('Only aim to crop and preprocess ( '+str(len(candidate_file_name_for_preprocessing))+' / '+str(original_dataset_size)+' ) maps...')\n",
    "    print('')\n",
    "\n",
    "    #print(len(candidate_file_name_for_preprocessing))\n",
    "    print(candidate_file_name_for_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ffab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(solutiona_dir+str('intermediate6/cropped_map')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate6/cropped_map'))\n",
    "if not os.path.exists(solutiona_dir+str('intermediate6/cropped_map(2)')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate6/cropped_map(2)'))\n",
    "if not os.path.exists(solutiona_dir+str('intermediate6/cropped_map_mask')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate6/cropped_map_mask'))\n",
    "if not os.path.exists(solutiona_dir+str('intermediate6/cropped_map_mask(2)')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate6/cropped_map_mask(2)'))\n",
    "\n",
    "if map_cropping == True:\n",
    "    runningtime_start=datetime.now()\n",
    "\n",
    "    if split_multiprocessing:\n",
    "        with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "            callback = pool.starmap_async(cropping_worker.cropping_worker, [(target_file_q,candidate_file_name_for_preprocessing[target_file_q], data_dir, solutiona_dir, crop_legend, ) for target_file_q in range(0, len(candidate_file_name_for_preprocessing))])\n",
    "            multiprocessing_results = callback.get()\n",
    "            \n",
    "            for this_map in multiprocessing_results:\n",
    "                this_crop_map = this_map\n",
    "                # plt.imshow(this_crop_map)\n",
    "                # plt.show()\n",
    "    else:\n",
    "        for target_file_q in range(0, len(candidate_file_name_for_preprocessing)):\n",
    "            cropping_worker.cropping_worker(target_file_q)\n",
    "    \n",
    "    print('time check _v0x:', datetime.now()-runningtime_start)\n",
    "\n",
    "else:\n",
    "    print('Cropping already done...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211b7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b118036",
   "metadata": {},
   "source": [
    "# Belows are for Polygon Extraction Only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4dc0d91",
   "metadata": {},
   "source": [
    "### Specify which maps to extract (map with polygon features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf2cf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file_name_for_polygon = []\n",
    "poly_legend_counter = []\n",
    "#poly_legend_counter_v2 = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if '.json' in file_name:\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        #print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        \n",
    "        poly_counter = 0\n",
    "        legend_counter = 0\n",
    "        poly_name_list = []\n",
    "\n",
    "        with open(test_json) as f:\n",
    "            gj = json.load(f)\n",
    "        for this_gj in gj['shapes']:\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names and '_pt' not in names and '_line' not in names:\n",
    "                print(names)\n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            if names not in poly_name_list:\n",
    "                poly_name_list.append(names)\n",
    "            legend_counter = legend_counter + 1\n",
    "            \n",
    "        if legend_counter > 0:\n",
    "            poly_counter = poly_counter + 1\n",
    "            poly_legend_counter.append(len(poly_name_list))\n",
    "            #poly_legend_counter.append(legend_counter)\n",
    "            #poly_legend_counter_v2.append(len(poly_name_list))\n",
    "        \n",
    "        if poly_counter > 0:\n",
    "            candidate_file_name_for_polygon.append(file_name)\n",
    "print(len(candidate_file_name_for_polygon))\n",
    "print(candidate_file_name_for_polygon)\n",
    "print(poly_legend_counter)\n",
    "#print(poly_legend_counter_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ba346",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_target_map = open('targeted_map.csv', 'r')\n",
    "data_target_map = list(csv.reader(file_target_map, delimiter=','))\n",
    "file_target_map.close()\n",
    "\n",
    "#print(data_target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e436acfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file_name_for_polygon_temp = candidate_file_name_for_polygon.copy()\n",
    "poly_legend_counter_temp = poly_legend_counter.copy()\n",
    "\n",
    "candidate_file_name_for_polygon = []\n",
    "poly_legend_counter = []\n",
    "\n",
    "for file_counter in range(0, len(candidate_file_name_for_polygon_temp)):\n",
    "    file_name = candidate_file_name_for_polygon_temp[file_counter]\n",
    "    #print(file_name.split('.')[0])\n",
    "    if any(file_name.split('.')[0] in target_map for target_map in data_target_map):\n",
    "        candidate_file_name_for_polygon.append(file_name)\n",
    "        poly_legend_counter.append(poly_legend_counter_temp[file_counter])\n",
    "\n",
    "print(len(candidate_file_name_for_polygon))\n",
    "print(candidate_file_name_for_polygon)\n",
    "print(poly_legend_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95e6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e07fa8",
   "metadata": {},
   "source": [
    "### Preprocessing for the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f4480",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists(solutiona_dir+str('intermediate7/')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate7/'))\n",
    "\n",
    "\n",
    "# import preprocessing_worker\n",
    "if map_preprocessing == True:\n",
    "    runningtime_start=datetime.now()\n",
    "\n",
    "    if split_multiprocessing:\n",
    "        with multiprocessing.Pool(int(PROCESSES/2)) as pool:\n",
    "            callback = pool.starmap_async(preprocessing_worker.preprocessing_worker, [(this_map,candidate_file_name_for_polygon[this_map], data_dir, solutiona_dir, crop_legend, ) for this_map in range(0, len(candidate_file_name_for_polygon))])\n",
    "            multiprocessing_results = callback.get()\n",
    "            \n",
    "            for this_map in multiprocessing_results:\n",
    "                this_crop_map = this_map\n",
    "                # plt.imshow(this_crop_map)\n",
    "                # plt.show()\n",
    "    else:\n",
    "        for this_map in range(0, len(candidate_file_name_for_polygon)):\n",
    "            preprocessing_worker.preprocessing_worker(this_map)\n",
    "    \n",
    "    print('time check _v00:', datetime.now()-runningtime_start)\n",
    "else:\n",
    "    print('Preprocessing already done...')\n",
    "\n",
    "# 27m 45.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c191c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask(given_size):\n",
    "    sliding_window_size = given_size\n",
    "    initial_mask = np.zeros((sliding_window_size*2+3,sliding_window_size*2+3), dtype=int)\n",
    "    center_j = sliding_window_size+1\n",
    "    center_i = sliding_window_size+1\n",
    "    initial_mask[center_j-1:center_j+2, center_i-1:center_i+2] = -1\n",
    "\n",
    "    initial_mask[center_j-3][center_i-1] = 2\n",
    "    initial_mask[center_j-3][center_i+1] = 2\n",
    "    initial_mask[center_j-2][center_i] = 2\n",
    "\n",
    "    initial_mask[center_j-1][center_i+3] = 4\n",
    "    initial_mask[center_j+1][center_i+3] = 4\n",
    "    initial_mask[center_j][center_i+2] = 4\n",
    "\n",
    "    initial_mask[center_j+3][center_i-1] = 6\n",
    "    initial_mask[center_j+3][center_i+1] = 6\n",
    "    initial_mask[center_j+2][center_i] = 6\n",
    "\n",
    "    initial_mask[center_j-1][center_i-3] = 8\n",
    "    initial_mask[center_j+1][center_i-3] = 8\n",
    "    initial_mask[center_j][center_i-2] = 8\n",
    "\n",
    "\n",
    "    for j in range(0, sliding_window_size-1):\n",
    "        for i in range(center_i-(sliding_window_size-2-j), center_i+(sliding_window_size-2-j)+1):\n",
    "            initial_mask[j][i] = 2\n",
    "\n",
    "    for j in range(sliding_window_size+3+1, sliding_window_size*2+3):\n",
    "        for i in range(center_i-(j-(sliding_window_size+3+1)), center_i+(j-(sliding_window_size+3+1))+1):\n",
    "            initial_mask[i][j] = 4\n",
    "\n",
    "    for j in range(sliding_window_size+3+1, sliding_window_size*2+3):\n",
    "        for i in range(center_i-(j-(sliding_window_size+3+1)), center_i+(j-(sliding_window_size+3+1))+1):\n",
    "            initial_mask[j][i] = 6\n",
    "\n",
    "    for j in range(0, sliding_window_size-1):\n",
    "        for i in range(center_i-(sliding_window_size-2-j), center_i+(sliding_window_size-2-j)+1):\n",
    "            initial_mask[i][j] = 8\n",
    "\n",
    "    initial_mask_arg = np.argwhere(initial_mask == 0)\n",
    "    for i, j in initial_mask_arg:\n",
    "        if i<=sliding_window_size and j<=sliding_window_size:\n",
    "            initial_mask[i][j] = 1\n",
    "        elif i<=sliding_window_size and j>=sliding_window_size:\n",
    "            initial_mask[i][j] = 3\n",
    "        elif i>=sliding_window_size and j>sliding_window_size:\n",
    "            initial_mask[i][j] = 5\n",
    "        elif i>=sliding_window_size and j<=sliding_window_size:\n",
    "            initial_mask[i][j] = 7\n",
    "    #print(initial_mask)\n",
    "\n",
    "\n",
    "    masking = []\n",
    "    for direction in range(0, 8):\n",
    "        masking.append(np.zeros((sliding_window_size*2+3,sliding_window_size*2+3), dtype=bool))\n",
    "    masking = np.array(masking)\n",
    "\n",
    "    for direction in range(0, 8):\n",
    "        initial_mask_arg = np.argwhere(initial_mask == (direction+1))\n",
    "        for i, j in initial_mask_arg:\n",
    "            masking[direction][i][j] = True\n",
    "    #print(masking.shape)\n",
    "\n",
    "    return masking\n",
    "\n",
    "def kernel_assign_white(img, i, j):\n",
    "    img[max(i-1, 0)][max(j-1, 0)] = 255\n",
    "    img[max(i-1, 0)][j] = 255\n",
    "    img[max(i-1, 0)][min(j+1, 0)] = 255\n",
    "    img[i][max(j-1, 0)] = 255\n",
    "    img[i][j] = 255\n",
    "    img[i][min(j+1, 0)] = 255\n",
    "    img[min(i+1, 0)][max(j-1, 0)] = 255\n",
    "    img[min(i+1, 0)][j] = 255\n",
    "    img[min(i+1, 0)][min(j+1, 0)] = 255\n",
    "\n",
    "def center_assign_white(img, i, j):\n",
    "    img[i][j] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a3c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24eacab2",
   "metadata": {},
   "source": [
    "### Generate boundary groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae004c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_boundary_groundtruth == True:\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/'))\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/Groundtruth/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/Groundtruth/'))\n",
    "    running_time_p = []\n",
    "    \n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(0, 2, 1):\n",
    "        map_name = candidate_file_name_for_polygon[target_file_q].replace('.json', '')\n",
    "        \n",
    "        file_path = os.path.join(data_dir, map_name)\n",
    "        runningtime_start=datetime.now()\n",
    "        \n",
    "\n",
    "        with open(file_path+'.json') as f:\n",
    "            gj = json.load(f)\n",
    "        \n",
    "        poly_counter_temp = 0\n",
    "        legend_name = []\n",
    "        candidate_file_path = []\n",
    "\n",
    "        for this_gj in gj['shapes']:\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            if names in legend_name:\n",
    "                continue\n",
    "            legend_name.append(names)\n",
    "\n",
    "            poly_counter_temp = poly_counter_temp + 1\n",
    "\n",
    "\n",
    "        for candidate_name in legend_name:\n",
    "            candidate_file_path.append(os.path.join(data_boundary_dir, (map_name+'_'+candidate_name+'.tif')))\n",
    "        print('Working on map: ' + map_name + ' (with legends: ' + str(len(candidate_file_path)) + ')')\n",
    "\n",
    "\n",
    "        \n",
    "        #targeted_groundtruth = []\n",
    "        hit_candidate = False\n",
    "        legend_counting = 0\n",
    "\n",
    "        #for candidate_polygon_groundtruth in os.listdir(data_boundary_dir):\n",
    "        for candidate_polygon_groundtruth in candidate_file_path:\n",
    "            if '.tif' in candidate_polygon_groundtruth:\n",
    "                if map_name in candidate_polygon_groundtruth: #[0: len(file_name)+1]:\n",
    "                    legend_counting = legend_counting + 1\n",
    "                    #this_candidate_groundtruth = os.path.join(data_boundary_dir, candidate_polygon_groundtruth)\n",
    "                    this_candidate_groundtruth = candidate_polygon_groundtruth\n",
    "\n",
    "                    this_candidate = cv2.imread(this_candidate_groundtruth)\n",
    "                    this_candidate = cv2.cvtColor(this_candidate, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    if hit_candidate == False:\n",
    "                        hit_candidate = True\n",
    "                        polygon_overlapped = np.zeros((this_candidate.shape[0],this_candidate.shape[1]),dtype=np.uint8)\n",
    "                        boundary_overlapped = np.zeros((this_candidate.shape[0],this_candidate.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                    this_candidate_temp = np.copy(this_candidate)\n",
    "                    this_candidate_temp[this_candidate > 0] = 1\n",
    "\n",
    "                    #dilate_kernel = np.ones((1, 1), np.uint8)\n",
    "                    dilate_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "                    dilate_image = cv2.dilate(this_candidate_temp, dilate_kernel, iterations=1)\n",
    "                    this_candidate_temp[dilate_image > 0] = 1 # dilated polygon\n",
    "\n",
    "                    polygon_subtract = cv2.subtract(this_candidate_temp, this_candidate)\n",
    "                    polygon_subtract[polygon_subtract > 0] = 1 # boundary for this polygon\n",
    "                    #print(np.unique(polygon_subtract))\n",
    "\n",
    "                    polygon_overlapped = cv2.add(polygon_overlapped, this_candidate_temp)\n",
    "                    #print(np.unique(polygon_overlapped))\n",
    "\n",
    "                    polygon_subtract[polygon_subtract > 0] = 255\n",
    "                    boundary_overlapped = cv2.bitwise_or(boundary_overlapped, polygon_subtract)\n",
    "                    #print(np.unique(boundary_overlapped))\n",
    "\n",
    "                    #targeted_groundtruth.append(this_candidate_groundtruth)\n",
    "\n",
    "\n",
    "        out_file_path0=solutiona_dir+'intermediate5/Groundtruth/'+map_name+'_polygon_overlapped.png'\n",
    "        cv2.imwrite(out_file_path0, polygon_overlapped)\n",
    "        out_file_path0=solutiona_dir+'intermediate5/Groundtruth/'+map_name+'_boundary_identified.png'\n",
    "        boundary_overlapped[boundary_overlapped > 0] = 255\n",
    "        cv2.imwrite(out_file_path0, boundary_overlapped)\n",
    "\n",
    "\n",
    "        this_running_time_p = datetime.now()-runningtime_start\n",
    "        print(this_running_time_p)\n",
    "        running_time_p.append(this_running_time_p)\n",
    "\n",
    "\n",
    "else:\n",
    "    print('Groundtruth for boundary is already computed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c4eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "97487110",
   "metadata": {},
   "source": [
    "### Attempt to boundary extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ffe09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(solutiona_dir+str('intermediate5/Extraction/')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate5/Extraction/'))\n",
    "    \n",
    "if generate_boundary_extraction == True:\n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "            img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "            img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "            img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "            img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            this_current_image = np.copy(img_rb)\n",
    "            overall_overlapping = np.zeros((this_current_image.shape[0], this_current_image.shape[1]), dtype='uint8')\n",
    "\n",
    "            # black_pixel_for_text\n",
    "            # black_text_for_text\n",
    "            # black_line_for_text // black_line_for_text = black_pixel_for_text - black_text_for_text\n",
    "            text_pattern_probability = True\n",
    "            img_backgroun_v0 = np.copy(img_rb)\n",
    "            img_backgroun_v0 = cv2.cvtColor(img_backgroun_v0, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "            lower_black_text = np.array([0])\n",
    "            upper_black_text = np.array([65])\n",
    "            mask_box_text0 = cv2.inRange(img_backgroun_v0, lower_black_text, upper_black_text)\n",
    "            res_box_text1 = cv2.bitwise_and(img_bound, img_bound, mask=mask_box_text0)\n",
    "            black_pixel_for_text = np.copy(res_box_text1)\n",
    "\n",
    "            threshold_text = cv2.medianBlur(res_box_text1,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Legend is always not considered\n",
    "            if True:\n",
    "                for this_gj in gj['shapes']:\n",
    "                    #print(this_gj)\n",
    "                    names = this_gj['label']\n",
    "                    features = this_gj['points']\n",
    "\n",
    "                    geoms = np.array(features)\n",
    "                    y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                    x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                    legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                    legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                    img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "                img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "                img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "                img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "                img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "            hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "            rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "            hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "            rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "            \n",
    "            poly_counter = 0\n",
    "            color_space = []\n",
    "            color_avg = []\n",
    "            color_avg2 = []\n",
    "            map_name = file_name.replace('.json', '')\n",
    "            legend_name = []\n",
    "            legend_name_check = []\n",
    "            extracted_legend_name = []\n",
    "\n",
    "\n",
    "            hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "            rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "            if not os.path.exists(solutiona_dir+'intermediate5/Extraction/'+map_name):\n",
    "                os.makedirs(solutiona_dir+'intermediate5/Extraction/'+map_name)\n",
    "\n",
    "\n",
    "\n",
    "            temp_legend_name = []\n",
    "            temp_legend_feature = []\n",
    "            for this_gj in gj['shapes']:\n",
    "                #if '_poly' not in names:\n",
    "                    #continue\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                \n",
    "                if '_poly' not in names:\n",
    "                    continue\n",
    "                if names in legend_name_check:\n",
    "                    continue\n",
    "\n",
    "                ### Read json source for the legend\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "                img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "\n",
    "\n",
    "                legend_name_check.append(names)\n",
    "                legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "                temp_legend_name.append(names.replace('_poly',''))\n",
    "                temp_legend_feature.append(img_legend)\n",
    "\n",
    "                poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "            \n",
    "            if split_multiprocessing == True:\n",
    "                with multiprocessing.Pool(int(PROCESSES*2)) as pool:\n",
    "                    callback = pool.starmap_async(extraction_step0_find_legend_in_map_worker.extraction_step0_find_legend_in_map_worker, [(this_poly, map_name, temp_legend_name[this_poly], temp_legend_feature[this_poly], solutiona_dir, threshold_text, img_crop_black, np.sum(img_bound), text_pattern_probability, print_intermediate_image, ) for this_poly in range(0, poly_counter)])\n",
    "                    multiprocessing_results = callback.get()\n",
    "\n",
    "                    for legend, overlapping in multiprocessing_results:\n",
    "                        overall_overlapping = cv2.bitwise_or(overall_overlapping, overlapping)\n",
    "                \n",
    "\n",
    "            out_file_path0=solutiona_dir+'intermediate5/Extraction/'+map_name+'_overall_text.png'\n",
    "            cv2.imwrite(out_file_path0, overall_overlapping)\n",
    "\n",
    "            inversed_overall = cv2.bitwise_and(img_crop_black, 255-overall_overlapping)\n",
    "            out_file_path0=solutiona_dir+'intermediate5/Extraction/'+map_name+'_overall_boundary.png'\n",
    "            cv2.imwrite(out_file_path0, inversed_overall)\n",
    "            \n",
    "\n",
    "            print('time checkpoint _vt0:', datetime.now()-runningtime_start)\n",
    "else:\n",
    "    print('No need to extract boundaries (extraction already done)...')\n",
    "\n",
    "\n",
    "# 21m 50.6s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45753918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6627de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_boundary_extraction == True:\n",
    "    #data_dir='validation'\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/'))\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/Extraction(2)/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/Extraction(2)/'))\n",
    "    \n",
    "\n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "        \n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "            img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "            img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "            img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "            img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Legend is always not considered\n",
    "            if True:\n",
    "                for this_gj in gj['shapes']:\n",
    "                    #print(this_gj)\n",
    "                    names = this_gj['label']\n",
    "                    features = this_gj['points']\n",
    "\n",
    "                    geoms = np.array(features)\n",
    "                    y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                    x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                    legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                    legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                    img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "                img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "                img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "                img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "                img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "            hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "            rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "            hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "            rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            laplacian = cv2.Laplacian(hsv_rb,cv2.CV_64F)\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_hsv_rb.png'\n",
    "                cv2.imwrite(out_file_path0, laplacian)\n",
    "            laplacian = cv2.Laplacian(rgb_rb,cv2.CV_64F)\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_rgb_rb.png'\n",
    "                cv2.imwrite(out_file_path0, laplacian)\n",
    "            laplacian = cv2.Laplacian(hsv_ms,cv2.CV_64F)\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_hsv_ms.png'\n",
    "                cv2.imwrite(out_file_path0, laplacian)\n",
    "            laplacian = cv2.Laplacian(rgb_ms,cv2.CV_64F)\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_rgb_ms.png'\n",
    "                cv2.imwrite(out_file_path0, laplacian)\n",
    "\n",
    "            for candidate_space in range(0,3):\n",
    "                img = np.copy(hsv_ms[:,:,candidate_space])\n",
    "                laplacian = cv2.Laplacian(img,cv2.CV_64F)\n",
    "                if print_intermediate_image == True:\n",
    "                    out_file_path0=solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_hsv_ms_'+str(candidate_space)+'.png'\n",
    "                    cv2.imwrite(out_file_path0, laplacian)\n",
    "\n",
    "else:\n",
    "    print('No need to extract boundaries...')\n",
    "\n",
    "# 11m 16.5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29095e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_boundary_extraction == True:\n",
    "    #data_dir='validation'\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/'))\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate5/Extraction(3)/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate5/Extraction(3)/'))\n",
    "    \n",
    "\n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "        \n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "\n",
    "            img_cand_1 = cv2.imread(solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_hsv_ms_1.png')\n",
    "            img_cand_1 = cv2.cvtColor(img_cand_1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_cand_2 = cv2.imread(solutiona_dir+'intermediate5/Extraction(2)/'+file_name.replace('.json', '')+'_hsv_ms_2.png')\n",
    "            img_cand_2 = cv2.cvtColor(img_cand_2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            dilate_kernel = np.ones((3,3), np.uint8)\n",
    "            img_cand_3 = cv2.dilate(img_cand_1, dilate_kernel, iterations=1)\n",
    "\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_hsv_ms_1_dilation.png'\n",
    "                cv2.imwrite(out_file_path0, img_cand_3)\n",
    "\n",
    "            img_cand_comb = cv2.add(img_cand_3, img_cand_2)\n",
    "\n",
    "            #erode_kernel = np.ones((1,1), np.uint8)\n",
    "            #img_cand_comb = cv2.erode(img_cand_comb, erode_kernel, iterations=1)\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_hsv_ms_1_combined.png'\n",
    "                cv2.imwrite(out_file_path0, img_cand_comb)\n",
    "\n",
    "            #img_cand_comb[img_cand_comb > 127] = 255\n",
    "            #img_cand_comb[img_cand_comb <= 127] = 0\n",
    "\n",
    "            #erode_kernel = np.ones((2,2), np.uint8)\n",
    "            #img_cand_comb = cv2.dilate(img_cand_comb, erode_kernel, iterations=1)\n",
    "            #img_cand_comb = cv2.erode(img_cand_comb, erode_kernel, iterations=1)\n",
    "\n",
    "            img_cand_comb[img_cand_comb > 255*0.05] = 255\n",
    "            img_cand_comb[img_cand_comb <= 255*0.05] = 0\n",
    "\n",
    "            img_cand_5 = cv2.imread(solutiona_dir+'intermediate5/Extraction/'+file_name.replace('.json', '')+'_overall_boundary.png')\n",
    "            img_cand_5 = cv2.cvtColor(img_cand_5, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #blur_radius = 3\n",
    "            #img_cand_5_blur = ndimage.gaussian_filter(img_cand_5, blur_radius)\n",
    "            #img_cand_5_blur[img_cand_5_blur > 0.25] = 255\n",
    "            #img_cand_5_blur[img_cand_5_blur <= 0.25] = 0\n",
    "\n",
    "            #erode_kernel = np.ones((5,5), np.uint8)\n",
    "            #img_cand_5_blur = cv2.dilate(img_cand_5, erode_kernel, iterations=1)\n",
    "            img_cand_5_blur = np.copy(img_cand_5)\n",
    "\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_boundary_blur.png'\n",
    "                cv2.imwrite(out_file_path0, img_cand_5_blur)\n",
    "            \n",
    "            #print(img_cand_comb.shape)\n",
    "            #print(img_cand_5_blur.shape)\n",
    "            img_cand_6 = cv2.bitwise_and(img_cand_comb, img_cand_5_blur)\n",
    "\n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_overall_boundary_candidate.png'\n",
    "                cv2.imwrite(out_file_path0, img_cand_6)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "else:\n",
    "    print('No need to extract boundaries (extraction already done)...')\n",
    "\n",
    "# 1m 44.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d7705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "990c55d9",
   "metadata": {},
   "source": [
    "### Generating Auxiliary Information for each legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f156f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if printing_auxiliary_information == True:\n",
    "    # auxiliary information needs to be printed:\n",
    "    ### number of legends in one map\n",
    "    ### range of H space for each legend\n",
    "    ### difference in (1) H space (2) RGB-min (3) RGB-dist to the nearest 10 other legends for each legend\n",
    "\n",
    "    #data_dir='validation'\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate9/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate9/'))\n",
    "\n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "        \n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "            img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "            img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "            img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            #img_boundary = cv2.imread(solutiona_dir+'intermediate5/Extraction/'+file_name.replace('.json', '')+'_overall_boundary.png')\n",
    "            img_boundary = cv2.imread(solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_overall_boundary_candidate.png')\n",
    "            img_boundary = cv2.cvtColor(img_boundary, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "            img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Legend is always not considered\n",
    "            if True:\n",
    "                for this_gj in gj['shapes']:\n",
    "                    #print(this_gj)\n",
    "                    names = this_gj['label']\n",
    "                    features = this_gj['points']\n",
    "\n",
    "                    geoms = np.array(features)\n",
    "                    y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                    x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                    legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                    legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                    img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "                img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "                img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "                img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "                img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "            hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "            rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "            hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "            rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            poly_counter = 0\n",
    "            color_space = []\n",
    "            color_avg = []\n",
    "            color_avg2 = []\n",
    "            color_dif = []\n",
    "            color_key_variety = []\n",
    "            map_name = file_name.replace('.json', '')\n",
    "            legend_name = []\n",
    "            legend_name_check = []\n",
    "            extracted_legend_name = []\n",
    "\n",
    "\n",
    "            hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "            rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "            if not os.path.exists(solutiona_dir+'intermediate7(2)/'+map_name):\n",
    "                os.makedirs(solutiona_dir+'intermediate7(2)/'+map_name)\n",
    "\n",
    "\n",
    "\n",
    "            for this_gj in gj['shapes']:\n",
    "                #if '_poly' not in names:\n",
    "                    #continue\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                \n",
    "                if '_poly' not in names:\n",
    "                    continue\n",
    "                if names in legend_name_check:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                legend_name_check.append(names)\n",
    "                legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "                poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "                ### There is no groundtruth for validation data\n",
    "                #print('training/'+map_name+'_'+names+'.tif')\n",
    "\n",
    "\n",
    "                ### Read json source for the legend\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "                img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "                \n",
    "                if print_intermediate_image == True:\n",
    "                    out_file_path0=solutiona_dir+'intermediate7(2)/'+map_name+'/'+map_name+'_'+names+'_legend.tif'\n",
    "                    cv2.imwrite(out_file_path0, img_legend)\n",
    "                \n",
    "                \n",
    "                img_legend = cv2.cvtColor(img_legend, cv2.COLOR_BGR2RGB)\n",
    "                img_legend = img_legend[int(img_legend.shape[0]/8):int(img_legend.shape[0]*7/8), int(img_legend.shape[1]/8):int(img_legend.shape[1]*7/8), :]\n",
    "                hsv_legend = cv2.cvtColor(img_legend, cv2.COLOR_RGB2HSV)\n",
    "                black_threshold = 30 #130\n",
    "                white_threshold = 250 #245\n",
    "\n",
    "                lower_black_rgb_trimmed0 = np.array([0,0,0])\n",
    "                upper_black_rgb_trimmed0 = np.array([130,130,130])\n",
    "                mask_test_img_legend = cv2.inRange(img_legend, lower_black_rgb_trimmed0, upper_black_rgb_trimmed0)\n",
    "                if np.sum(mask_test_img_legend == 255) > np.sum(img_legend > 0) * 0.25:\n",
    "                    black_threshold = 30\n",
    "                \n",
    "                rgb_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                hsv_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                rgb_trimmed = rgb_trimmed.astype(float)\n",
    "                hsv_trimmed = hsv_trimmed.astype(float)\n",
    "                for dimension in range(0, 3):\n",
    "                    rgb_trimmed[dimension] = np.copy(img_legend[:,:,dimension]).astype(float)\n",
    "                    hsv_trimmed[dimension] = np.copy(hsv_legend[:,:,dimension]).astype(float)\n",
    "\n",
    "                rgb_trimmed_temp = np.copy(rgb_trimmed)\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "                if np.sum(np.isnan(hsv_trimmed)) >= (hsv_trimmed.shape[0]*hsv_trimmed.shape[1]*hsv_trimmed.shape[2]):\n",
    "                    color_space_holder = []\n",
    "                    rgb_lower_box = np.array((0,0,0), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((0,0,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                    rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                    color_avg_holder = np.array((0,0,0), dtype='uint8')\n",
    "                    color_avg_holder2 = np.array((0,0,0), dtype='uint8')\n",
    "                else:\n",
    "                    color_space_holder = []\n",
    "                    hsv_lower_box = np.array([int(np.nanquantile(hsv_trimmed[0],.2)),int(np.nanquantile(hsv_trimmed[1],.1)),int(np.nanquantile(hsv_trimmed[2],.1))]) #.2\n",
    "                    hsv_upper_box = np.array([int(np.nanquantile(hsv_trimmed[0],.8)),int(np.nanquantile(hsv_trimmed[1],.9)),int(np.nanquantile(hsv_trimmed[2],.9))]) #.8\n",
    "                    color_space_holder.append(hsv_lower_box)\n",
    "                    color_space_holder.append(hsv_upper_box)\n",
    "                    hsv_space[int(np.nanquantile(hsv_trimmed[0],.2)): int(np.nanquantile(hsv_trimmed[0],.8))] += poly_counter\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.2)),int(np.nanquantile(rgb_trimmed[1],.2)),int(np.nanquantile(rgb_trimmed[2],.2))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.8)),int(np.nanquantile(rgb_trimmed[1],.8)),int(np.nanquantile(rgb_trimmed[2],.8))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_space[int(np.nanquantile(rgb_trimmed[0],.3)): int(np.nanquantile(rgb_trimmed[0],.7)), int(np.nanquantile(rgb_trimmed[1],.3)): int(np.nanquantile(rgb_trimmed[1],.7)), int(np.nanquantile(rgb_trimmed[2],.3)): int(np.nanquantile(rgb_trimmed[2],.7))] = poly_counter\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.1)),int(np.nanquantile(rgb_trimmed[1],.1)),int(np.nanquantile(rgb_trimmed[2],.1))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.9)),int(np.nanquantile(rgb_trimmed[1],.9)),int(np.nanquantile(rgb_trimmed[2],.9))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.05)),int(np.nanquantile(rgb_trimmed[1],.05)),int(np.nanquantile(rgb_trimmed[2],.05))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.95)),int(np.nanquantile(rgb_trimmed[1],.95)),int(np.nanquantile(rgb_trimmed[2],.95))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.03)),int(np.nanquantile(rgb_trimmed[1],.03)),int(np.nanquantile(rgb_trimmed[2],.03))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.97)),int(np.nanquantile(rgb_trimmed[1],.97)),int(np.nanquantile(rgb_trimmed[2],.97))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.02)),int(np.nanquantile(rgb_trimmed[1],.02)),int(np.nanquantile(rgb_trimmed[2],.02))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.98)),int(np.nanquantile(rgb_trimmed[1],.98)),int(np.nanquantile(rgb_trimmed[2],.98))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "                    rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.01)),int(np.nanquantile(rgb_trimmed[1],.01)),int(np.nanquantile(rgb_trimmed[2],.01))])\n",
    "                    rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.99)),int(np.nanquantile(rgb_trimmed[1],.99)),int(np.nanquantile(rgb_trimmed[2],.99))])\n",
    "                    color_space_holder.append(rgb_lower_box)\n",
    "                    color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                    color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0],.5)),int(np.nanquantile(rgb_trimmed[1],.5)),int(np.nanquantile(rgb_trimmed[2],.5))])\n",
    "                    color_avg_holder2 = np.array([int(np.nanquantile(hsv_trimmed[0],.5)),int(np.nanquantile(hsv_trimmed[1],.5)),int(np.nanquantile(hsv_trimmed[2],.5))])\n",
    "\n",
    "                color_space.append(color_space_holder)\n",
    "                color_avg.append(color_avg_holder)\n",
    "                color_avg2.append(color_avg_holder2)\n",
    "\n",
    "                try:\n",
    "                    color_dif_in_h_space = int(np.nanquantile(hsv_trimmed[0],.8)) - int(np.nanquantile(hsv_trimmed[0],.2))\n",
    "                except:\n",
    "                    color_dif_in_h_space = -1\n",
    "                color_dif.append(color_dif_in_h_space)\n",
    "\n",
    "                color_key_variety_counting = max(0, np.unique(hsv_trimmed[0]).shape[0]-1)\n",
    "                color_key_variety.append(color_key_variety_counting)\n",
    "\n",
    "            print('time checkpoint _v0:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "            ans_category = np.zeros((poly_counter+1, img_rb.shape[0], img_rb.shape[1]), dtype='uint8')\n",
    "\n",
    "            blank = np.ones((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)*255\n",
    "            ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "            #print(legend_name)\n",
    "            #print(color_space)\n",
    "\n",
    "\n",
    "        \n",
    "        def extraction_step0_auxiliary_info(legend, map_name, legend_name, solutiona_dir, print_intermediate_image, all_color_avg, all_color_avg2, color_dif_value, color_key_variety_value, this_poly_value, poly_counter_value, subregion_ratio_value, grayregion_ratio_value, blackregion_ratio_value, color_variety_value, legend_color_range_set):\n",
    "            rgb_dif = np.zeros((poly_counter_value-1, 3), dtype='uint8')\n",
    "            hsv_dif = np.zeros((poly_counter_value-1, 3), dtype='uint8')\n",
    "            #rgb_dif = []\n",
    "            #hsv_dif = []\n",
    "\n",
    "            counting_dif = 0\n",
    "            for counter_legend in range(0, poly_counter_value):\n",
    "                if counter_legend == this_poly_value:\n",
    "                    continue\n",
    "                rgb_dif[counting_dif, :] = abs(all_color_avg[counter_legend, :] - all_color_avg[this_poly_value, :])\n",
    "                hsv_dif[counting_dif, :] = abs(all_color_avg2[counter_legend, :] - all_color_avg2[this_poly_value, :])\n",
    "                counting_dif += 1\n",
    "            \n",
    "            #print(rgb_dif)\n",
    "\n",
    "            #if print_intermediate_image == True:\n",
    "                #out_file_path0=solutiona_dir+'intermediate7(2)/'+map_name+'/'+map_name+'_'+legend_name[legend]+'_poly_c0_x.png'\n",
    "            #print(hsv_dif_h_space)\n",
    "\n",
    "            #print(np.sort(rgb_dif[:, 0]))\n",
    "            #print(np.sort(rgb_dif[:, 1]))\n",
    "            #print(np.sort(rgb_dif[:, 2]))\n",
    "\n",
    "            #print('name')\n",
    "            concat_name = str(map_name)+'_'+str(legend_name)+'_poly'\n",
    "            #print(concat_name)\n",
    "\n",
    "            #print('H space')\n",
    "            output_values = np.ones((10), dtype='uint8')*180\n",
    "            if counting_dif > 0:\n",
    "                output_values[0: min(10, counting_dif)] = np.sort(hsv_dif[:, 0])[0: min(10,counting_dif)]\n",
    "            #print(output_values)\n",
    "\n",
    "            #print('RGB-min')\n",
    "            output_values2 = np.ones((10), dtype='uint8')*180\n",
    "            if counting_dif > 0:\n",
    "                output_values2[0: min(10, counting_dif)] = np.sort(np.min(rgb_dif, axis=1))[0: min(10,counting_dif)]\n",
    "            #print(output_values2)\n",
    "\n",
    "            #print('RGB-dist')\n",
    "            rgb_dif_distances = np.sqrt(np.sum(rgb_dif**2,axis=1))\n",
    "            rgb_dif_distances_int = (np.rint(rgb_dif_distances)).astype(int)\n",
    "            output_values3 = np.ones((10), dtype='uint8')*180\n",
    "            if counting_dif > 0:\n",
    "                output_values3[0: min(10, counting_dif)] = np.sort(rgb_dif_distances_int)[0: min(10,counting_dif)]\n",
    "            #print(output_values3)\n",
    "\n",
    "            #print('strict range in h space in this key')\n",
    "            #print((color_dif_value+1))\n",
    "\n",
    "            #print('number of distinct colors in this key')\n",
    "            #print(color_key_variety_value)\n",
    "\n",
    "            #print('===')\n",
    "            #print('number of keys (legends) in map (/100.0)')\n",
    "            #print((poly_counter_value/100.0))\n",
    "\n",
    "            #print('ratio of subregion')\n",
    "            #print(subregion_ratio_value)\n",
    "\n",
    "            #print('ratio of grayregion')\n",
    "            #print(grayregion_ratio_value)\n",
    "            \n",
    "            #print('ratio of blackregion')\n",
    "            #print(blackregion_ratio_value)\n",
    "\n",
    "            #print('number of distinct colors (h space) in subregion (/180.0)')\n",
    "            #print(color_variety_value)\n",
    "\n",
    "            #print('color range (r/g/b space, h space) of all keys (/255.0 or /180.0)')\n",
    "            #print(legend_color_range_set)\n",
    "\n",
    "            if print_intermediate_image == True:\n",
    "                if os.path.isfile(solutiona_dir+'intermediate9/'+'auxiliary_info.csv') == False:\n",
    "                    with open(solutiona_dir+'intermediate9/'+'auxiliary_info.csv','w') as fd:\n",
    "                        fd.write('Map_name,Key_name')\n",
    "                        for looping in range(0, 10):\n",
    "                            fd.write(',Nearest_H_dist('+str(looping)+')')\n",
    "                        for looping in range(0, 10):\n",
    "                            fd.write(',Nearest_RGB_min('+str(looping)+')')\n",
    "                        for looping in range(0, 10):\n",
    "                            fd.write(',Nearest_RGB_dist('+str(looping)+')')\n",
    "                        fd.write(',strict_range_H,number_of_H_in_key')\n",
    "                        fd.write(',number_of_keys,ratio_subregion,ratio_grayregion,ratio_blackregion,number_of_H_in_map,color_range_R_across_keys,color_range_G_across_keys,color_range_B_across_keys,color_range_H_across_keys')\n",
    "                        fd.write('\\n')\n",
    "                        fd.close()\n",
    "                with open(solutiona_dir+'intermediate9/'+'auxiliary_info.csv','a') as fd:\n",
    "                    fd.write(map_name+','+concat_name)\n",
    "                    for looping in range(0, 10):\n",
    "                        fd.write(','+str(output_values[looping]))\n",
    "                    for looping in range(0, 10):\n",
    "                        fd.write(','+str(output_values2[looping]))\n",
    "                    for looping in range(0, 10):\n",
    "                        fd.write(','+str(output_values3[looping]))\n",
    "                    fd.write(','+str(color_dif_value+1)+','+str(color_key_variety_value))\n",
    "\n",
    "                    fd.write(','+str(poly_counter_value/100.0)+','+str(subregion_ratio_value)+','+str(grayregion_ratio_value)+','+str(blackregion_ratio_value)+','+str(color_variety_value))\n",
    "                    for looping in range(0, 4):\n",
    "                        fd.write(','+str(legend_color_range_set[looping]))\n",
    "                    fd.write('\\n')\n",
    "                    fd.close()\n",
    "\n",
    "            return\n",
    "        \n",
    "        \n",
    "\n",
    "        img_bound00 = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "        img_bound00 = cv2.cvtColor(img_bound00, cv2.COLOR_BGR2GRAY)\n",
    "        img_bound00[img_bound00 > 0] = 1\n",
    "        subregion_ratio = (np.sum(img_bound00)) / (img_bound00.shape[0]*img_bound00.shape[1])\n",
    "\n",
    "        img_crop_gray00 = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "        img_crop_black00 = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "        img_crop_gray00 = cv2.cvtColor(img_crop_gray00, cv2.COLOR_BGR2GRAY)\n",
    "        img_crop_black00 = cv2.cvtColor(img_crop_black00, cv2.COLOR_BGR2GRAY)\n",
    "        img_crop_gray00[img_crop_gray00 > 0] = 1\n",
    "        img_crop_black00[img_crop_black00 > 0] = 1\n",
    "        grayregion_ratio = (np.sum(img_crop_gray00)) / (np.sum(img_bound00))\n",
    "        blackregion_ratio = (np.sum(img_crop_black00)) / (np.sum(img_bound00))\n",
    "\n",
    "        color_variety = np.unique(hsv_rb[:,:,0]).shape[0] / 180.0\n",
    "\n",
    "        all_color_avg_np = np.array(color_avg)\n",
    "        all_color_avg_np2 = np.array(color_avg2)\n",
    "\n",
    "        legend_color_range_rgb_r_space = np.max(all_color_avg_np2, axis=0)[0] - np.min(all_color_avg_np2, axis=0)[0]\n",
    "        legend_color_range_rgb_g_space = np.max(all_color_avg_np2, axis=0)[1] - np.min(all_color_avg_np2, axis=0)[1]\n",
    "        legend_color_range_rgb_b_space = np.max(all_color_avg_np2, axis=0)[2] - np.min(all_color_avg_np2, axis=0)[2]\n",
    "        legend_color_range_hsv_h_space = np.max(all_color_avg_np2, axis=0)[0] - np.min(all_color_avg_np2, axis=0)[0]\n",
    "        legend_color_range = [legend_color_range_rgb_r_space / 255.0, legend_color_range_rgb_g_space / 255.0, legend_color_range_rgb_b_space / 255.0, legend_color_range_hsv_h_space / 180.0]\n",
    "\n",
    "        if os.path.isfile(solutiona_dir+'intermediate9/'+'auxiliary_info.csv') == False:\n",
    "            with open(solutiona_dir+'intermediate9/'+'auxiliary_info.csv','w') as fd:\n",
    "                fd.write('Map_name,Key_name')\n",
    "                for looping in range(0, 10):\n",
    "                    fd.write(',Nearest_H_dist('+str(looping)+')')\n",
    "                for looping in range(0, 10):\n",
    "                    fd.write(',Nearest_RGB_min('+str(looping)+')')\n",
    "                for looping in range(0, 10):\n",
    "                    fd.write(',Nearest_RGB_dist('+str(looping)+')')\n",
    "                fd.write(',strict_range_H,number_of_H_in_key')\n",
    "                fd.write(',number_of_keys,ratio_subregion,ratio_grayregion,ratio_blackregion,number_of_H_in_map,color_range_R_across_keys,color_range_G_across_keys,color_range_B_across_keys,color_range_H_across_keys')\n",
    "                fd.write('\\n')\n",
    "                fd.close()\n",
    "\n",
    "        print('time checkpoint _v1:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "        \n",
    "        for this_poly in range(0, poly_counter):\n",
    "            extraction_step0_auxiliary_info(this_poly, map_name, legend_name[this_poly], solutiona_dir, print_intermediate_image, all_color_avg_np, all_color_avg_np2, color_dif[this_poly], color_key_variety[this_poly], this_poly, poly_counter, subregion_ratio, grayregion_ratio, blackregion_ratio, color_variety, legend_color_range)\n",
    "        \n",
    "        print('time checkpoint _v2:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "# 7m 52.0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c3567c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a02f35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8e21d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947695c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f29539c",
   "metadata": {},
   "source": [
    "### Generating Groundtruth of Recolored Map (for reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2f4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "recoloring_groundtruth = True\n",
    "if preprocessing_recoloring == True and recoloring_groundtruth == True:\n",
    "    print('Applying recoloring...')\n",
    "\n",
    "    #data_dir='validation'\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate8/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate8/'))\n",
    "    \n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "\n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "            \n",
    "            poly_counter = 0\n",
    "            color_avg = []\n",
    "            map_name = file_name.replace('.json', '')\n",
    "            legend_name = []\n",
    "            legend_name_check = []\n",
    "            extracted_legend_name = []\n",
    "\n",
    "\n",
    "            hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "            rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "\n",
    "            for this_gj in gj['shapes']:\n",
    "                #if '_poly' not in names:\n",
    "                    #continue\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                \n",
    "                if '_poly' not in names:\n",
    "                    continue\n",
    "                if names in legend_name_check:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                legend_name_check.append(names)\n",
    "                legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "                poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "                ### There is no groundtruth for validation data\n",
    "                #print('training/'+map_name+'_'+names+'.tif')\n",
    "\n",
    "\n",
    "                ### Read json source for the legend\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "                img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "                \n",
    "                \n",
    "                img_legend = cv2.cvtColor(img_legend, cv2.COLOR_BGR2RGB)\n",
    "                img_legend = img_legend[int(img_legend.shape[0]/8):int(img_legend.shape[0]*7/8), int(img_legend.shape[1]/8):int(img_legend.shape[1]*7/8), :]\n",
    "                hsv_legend = cv2.cvtColor(img_legend, cv2.COLOR_RGB2HSV)\n",
    "                black_threshold = 30 #130\n",
    "                white_threshold = 250 #245\n",
    "\n",
    "                lower_black_rgb_trimmed0 = np.array([0,0,0])\n",
    "                upper_black_rgb_trimmed0 = np.array([130,130,130])\n",
    "                mask_test_img_legend = cv2.inRange(img_legend, lower_black_rgb_trimmed0, upper_black_rgb_trimmed0)\n",
    "                if np.sum(mask_test_img_legend == 255) > np.sum(img_legend > 0) * 0.25:\n",
    "                    black_threshold = 30\n",
    "                \n",
    "                rgb_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                hsv_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                rgb_trimmed = rgb_trimmed.astype(float)\n",
    "                hsv_trimmed = hsv_trimmed.astype(float)\n",
    "                for dimension in range(0, 3):\n",
    "                    rgb_trimmed[dimension] = np.copy(img_legend[:,:,dimension]).astype(float)\n",
    "                    hsv_trimmed[dimension] = np.copy(hsv_legend[:,:,dimension]).astype(float)\n",
    "\n",
    "                rgb_trimmed_temp = np.copy(rgb_trimmed)\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "                if np.sum(np.isnan(hsv_trimmed)) >= (hsv_trimmed.shape[0]*hsv_trimmed.shape[1]*hsv_trimmed.shape[2]):\n",
    "                    color_avg_holder = np.array((0,0,0), dtype='uint8')\n",
    "                else:\n",
    "                    color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0],.5)),int(np.nanquantile(rgb_trimmed[1],.5)),int(np.nanquantile(rgb_trimmed[2],.5))])\n",
    "                color_avg.append(color_avg_holder)\n",
    "\n",
    "            print('time checkpoint _v0:', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "            #for this_poly in range(0, poly_counter):\n",
    "                #print(legend_name[this_poly], color_avg[this_poly])\n",
    "            \n",
    "            candidate_file_path = []\n",
    "            for this_poly in range(0, poly_counter):\n",
    "                if os.path.isfile(os.path.join(data_boundary_dir, (map_name+'_'+legend_name[this_poly]+'_poly.tif'))) == True:\n",
    "                    candidate_file_path.append(os.path.join(data_boundary_dir, (map_name+'_'+legend_name[this_poly]+'_poly.tif')))\n",
    "            print('Working on map: ' + map_name + ' (with legends: ' + str(len(candidate_file_path)) + ')')\n",
    "\n",
    "            if len(candidate_file_path) == 0:\n",
    "                print('no groundtruth provided...')\n",
    "            \n",
    "\n",
    "            base_canvas = np.zeros((img000.shape[0], img000.shape[1], 3), dtype=np.uint8)\n",
    "            legend_counting = 0\n",
    "\n",
    "            #for candidate_polygon_groundtruth in os.listdir(data_boundary_dir):\n",
    "            for this_poly in range(0, len(candidate_file_path)):\n",
    "                candidate_polygon_groundtruth = candidate_file_path[this_poly]\n",
    "                if '.tif' in candidate_polygon_groundtruth:\n",
    "                    if map_name in candidate_polygon_groundtruth: #[0: len(file_name)+1]:\n",
    "                        legend_counting = legend_counting + 1\n",
    "                        #this_candidate_groundtruth = os.path.join(data_boundary_dir, candidate_polygon_groundtruth)\n",
    "                        this_candidate_groundtruth = candidate_polygon_groundtruth\n",
    "\n",
    "                        candidate_canvas = np.full((img000.shape[0], img000.shape[1], 3), color_avg[this_poly], dtype=np.uint8)\n",
    "\n",
    "                        this_candidate = cv2.imread(this_candidate_groundtruth)\n",
    "                        this_candidate = cv2.cvtColor(this_candidate, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                        candidate_canvas = cv2.bitwise_and(candidate_canvas, candidate_canvas, mask=this_candidate)\n",
    "                        base_canvas = cv2.add(base_canvas, candidate_canvas)\n",
    "\n",
    "                        #targeted_groundtruth.append(this_candidate_groundtruth)\n",
    "\n",
    "\n",
    "            out_file_path0=solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring.png'\n",
    "            base_canvas = cv2.cvtColor(base_canvas, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(out_file_path0, base_canvas)\n",
    "\n",
    "\n",
    "else:\n",
    "    print('No need to generate the groundtruth for recoloring...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9491f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c919e64f",
   "metadata": {},
   "source": [
    "### Preprocessing for Recoloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocessing_recoloring == True:\n",
    "    print('Applying recoloring...')\n",
    "\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate8/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate8/'))\n",
    "    \n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "        \n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "            img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "            img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "            img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "            img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "            img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Legend is always not considered\n",
    "            if True:\n",
    "                for this_gj in gj['shapes']:\n",
    "                    #print(this_gj)\n",
    "                    names = this_gj['label']\n",
    "                    features = this_gj['points']\n",
    "\n",
    "                    geoms = np.array(features)\n",
    "                    y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                    x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                    legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                    legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                    img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "                img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "                img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "                img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "                img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "            hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "            rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "            hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "            rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            poly_counter = 0\n",
    "            #color_space = []\n",
    "            color_avg = []\n",
    "            color_avg2 = []\n",
    "            color_set_avg = []\n",
    "            map_name = file_name.replace('.json', '')\n",
    "            legend_name = []\n",
    "            legend_name_check = []\n",
    "            extracted_legend_name = []\n",
    "\n",
    "\n",
    "            hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "            rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "            if not os.path.exists(solutiona_dir+'intermediate7(2)/'+map_name):\n",
    "                os.makedirs(solutiona_dir+'intermediate7(2)/'+map_name)\n",
    "\n",
    "\n",
    "\n",
    "            for this_gj in gj['shapes']:\n",
    "                #if '_poly' not in names:\n",
    "                    #continue\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                \n",
    "                if '_poly' not in names:\n",
    "                    continue\n",
    "                if names in legend_name_check:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                legend_name_check.append(names)\n",
    "                legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "                poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "                ### There is no groundtruth for validation data\n",
    "                #print('training/'+map_name+'_'+names+'.tif')\n",
    "\n",
    "\n",
    "                ### Read json source for the legend\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "                img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "                \n",
    "                if print_intermediate_image == True:\n",
    "                    out_file_path0=solutiona_dir+'intermediate7(2)/'+map_name+'/'+map_name+'_'+names+'_legend.tif'\n",
    "                    cv2.imwrite(out_file_path0, img_legend)\n",
    "                \n",
    "                \n",
    "                img_legend = cv2.cvtColor(img_legend, cv2.COLOR_BGR2RGB)\n",
    "                img_legend = img_legend[int(img_legend.shape[0]/8):int(img_legend.shape[0]*7/8), int(img_legend.shape[1]/8):int(img_legend.shape[1]*7/8), :]\n",
    "                hsv_legend = cv2.cvtColor(img_legend, cv2.COLOR_RGB2HSV)\n",
    "                black_threshold = 30 #130\n",
    "                white_threshold = 250 #245\n",
    "\n",
    "                lower_black_rgb_trimmed0 = np.array([0,0,0])\n",
    "                upper_black_rgb_trimmed0 = np.array([130,130,130])\n",
    "                mask_test_img_legend = cv2.inRange(img_legend, lower_black_rgb_trimmed0, upper_black_rgb_trimmed0)\n",
    "                if np.sum(mask_test_img_legend == 255) > np.sum(img_legend > 0) * 0.25:\n",
    "                    black_threshold = 30\n",
    "                \n",
    "                rgb_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                hsv_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "                rgb_trimmed = rgb_trimmed.astype(float)\n",
    "                hsv_trimmed = hsv_trimmed.astype(float)\n",
    "                for dimension in range(0, 3):\n",
    "                    rgb_trimmed[dimension] = np.copy(img_legend[:,:,dimension]).astype(float)\n",
    "                    hsv_trimmed[dimension] = np.copy(hsv_legend[:,:,dimension]).astype(float)\n",
    "\n",
    "                rgb_trimmed_temp = np.copy(rgb_trimmed)\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "\n",
    "                rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "                hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "\n",
    "                #color_preset = [.2, .3, .35, .4, .45, .5, .55, .6, .65, .7, .8]\n",
    "                color_preset = [.3, .4, .45, .5, .55, .6, .7]\n",
    "\n",
    "                if np.sum(np.isnan(hsv_trimmed)) >= (hsv_trimmed.shape[0]*hsv_trimmed.shape[1]*hsv_trimmed.shape[2]):\n",
    "                    color_space_holder2 = []\n",
    "                    for color_preseted in color_preset:\n",
    "                        color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed_temp[0], color_preseted)),int(np.nanquantile(rgb_trimmed_temp[1], color_preseted)),int(np.nanquantile(rgb_trimmed_temp[2], color_preseted))])\n",
    "                        color_space_holder2.append(color_avg_holder)\n",
    "\n",
    "                    color_avg_holder = np.array((0,0,0), dtype='uint8')\n",
    "                    color_avg_holder2 = np.array((0,0,0), dtype='uint8')\n",
    "                else:\n",
    "                    color_space_holder2 = []\n",
    "                    for color_preseted in color_preset:\n",
    "                        color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0], color_preseted)),int(np.nanquantile(rgb_trimmed[1], color_preseted)),int(np.nanquantile(rgb_trimmed[2], color_preseted))])\n",
    "                        color_space_holder2.append(color_avg_holder)\n",
    "                    \n",
    "                    color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0],.5)),int(np.nanquantile(rgb_trimmed[1],.5)),int(np.nanquantile(rgb_trimmed[2],.5))])\n",
    "                    color_avg_holder2 = np.array([int(np.nanquantile(hsv_trimmed[0],.5)),int(np.nanquantile(hsv_trimmed[1],.5)),int(np.nanquantile(hsv_trimmed[2],.5))])\n",
    "\n",
    "                #color_avg.append(color_avg_holder)\n",
    "                color_set_avg.append(color_space_holder2)\n",
    "                color_avg2.append(color_avg_holder2)\n",
    "\n",
    "            print('time checkpoint _v0:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "            ans_category = np.zeros((poly_counter+1, img_rb.shape[0], img_rb.shape[1]), dtype='uint8')\n",
    "\n",
    "            blank = np.ones((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)*255\n",
    "            ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "            #print(legend_name)\n",
    "            #print(color_space)\n",
    "\n",
    "\n",
    "            mapping_color_to_color_set = []\n",
    "            for color_set_id in range(0, len(color_set_avg)):\n",
    "                for color_id in range(0, len(color_set_avg[color_set_id])):\n",
    "                    color_avg.append(color_set_avg[color_set_id][color_id])\n",
    "                    mapping_color_to_color_set.append(color_set_id)\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            total_color_set = len(color_set_avg)\n",
    "\n",
    "            # add contour/ background color\n",
    "            color_avg.append(np.array([0,0,0])) # black (contour, text)\n",
    "            color_avg2.append(np.array([0,0,0]))\n",
    "            mapping_color_to_color_set.append(total_color_set)\n",
    "            total_color_set += 1\n",
    "\n",
    "            color_avg.append(np.array([255,255,255])) # white (background)\n",
    "            color_avg2.append(np.array([255,255,255]))\n",
    "            mapping_color_to_color_set.append(total_color_set)\n",
    "            total_color_set += 1\n",
    "\n",
    "            check_ocean = False\n",
    "            ### check if an ocean-like color is already included\n",
    "            np_color_avg = np.array(color_avg)\n",
    "            ocean_cand = []\n",
    "            ocean_cand.append([218, 240, 254]) # ocean\n",
    "            np_ocean_cand = np.array(ocean_cand)\n",
    "            #print(np.isin(np_ocean_cand, np_color_avg).all(-1).any(-1))\n",
    "            #print((abs(np.subtract(np_ocean_cand, np_color_avg))))\n",
    "            #print(np_color_avg.shape[0])\n",
    "\n",
    "            check_ocean = ((abs(np.subtract(np_ocean_cand, np_color_avg))) < (max(5, 15-int(np_color_avg.shape[0]/10)))).all(-1).any(-1)\n",
    "            #print(((abs(np.subtract(np_ocean_cand, np_color_avg))) < (max(5, 10-int(np_color_avg.shape[0]/10)))).all(-1).any(-1))\n",
    "            if check_ocean == False:\n",
    "                color_avg.append(np.array([218,240,254])) # blue (ocean)\n",
    "                color_avg2.append(np.array([218,240,254]))\n",
    "                mapping_color_to_color_set.append(total_color_set)\n",
    "                total_color_set += 1\n",
    "                print('Add ocean color...')\n",
    "            else:\n",
    "                print('Ocean-like color is already included...')\n",
    "\n",
    "            print('total # of colors:', len(color_avg))\n",
    "            print('total # of keys:', total_color_set)\n",
    "            #print(color_avg)\n",
    "            #print(mapping_color_to_color_set)\n",
    "\n",
    "\n",
    "            temp_mapping = np.array(mapping_color_to_color_set)\n",
    "            mapping_color_set_to_color_prob = np.empty(shape=(total_color_set, len(color_avg)))\n",
    "            mapping_color_set_to_color_prob.fill(0.0)\n",
    "\n",
    "            for set_id in range(0, total_color_set):\n",
    "                targeted_index = np.where(temp_mapping == set_id)\n",
    "                #print(targeted_index[0])\n",
    "                #print(targeted_index[0].shape[0])\n",
    "\n",
    "                for targeted_id in targeted_index[0]:\n",
    "                    mapping_color_set_to_color_prob[set_id][targeted_id] = 1/targeted_index[0].shape[0]\n",
    "\n",
    "            #print(mapping_color_set_to_color_prob.shape)\n",
    "            #print(mapping_color_set_to_color_prob)\n",
    "\n",
    "            mapping_color_set_to_color_prob_tp = np.copy(mapping_color_set_to_color_prob)\n",
    "            mapping_color_set_to_color_prob_tp = np.transpose(mapping_color_set_to_color_prob_tp)\n",
    "\n",
    "\n",
    "            # If there is color shift for all legends, but this section is never used for the final solution.\n",
    "            minimal_grid_size = 1000\n",
    "            distance_kernel = np.ones((5,5)) / 25.0\n",
    "            distance_kernel = distance_kernel[:, :, None]\n",
    "\n",
    "            smoothing_map_experimental = True\n",
    "            if smoothing_map_experimental == True:\n",
    "\n",
    "                img_bound_argwhere = np.argwhere(img_bound)\n",
    "                (ystart, xstart), (ystop, xstop) = img_bound_argwhere.min(0), img_bound_argwhere.max(0) + 1\n",
    "\n",
    "                gridize_processing = True\n",
    "                y_shape = ystop-ystart\n",
    "                x_shape = xstop-xstart\n",
    "                if gridize_processing == True and y_shape > minimal_grid_size and x_shape > minimal_grid_size:\n",
    "                    repaste_image = np.zeros((img_bound.shape[0], img_bound.shape[1], 3), dtype='uint8')\n",
    "                    repaste_index = np.zeros((img_bound.shape[0], img_bound.shape[1], 1), dtype='uint8')\n",
    "                    grid_counting = math.ceil(y_shape/minimal_grid_size) * math.ceil(x_shape/minimal_grid_size)\n",
    "                    grid_completed = 0\n",
    "\n",
    "                    for r in range(0, math.ceil(y_shape/minimal_grid_size)):\n",
    "                        for c in range(0, math.ceil(x_shape/minimal_grid_size)):\n",
    "                            r_0 = ystart + r*minimal_grid_size\n",
    "                            r_1 = ystart + min(r*minimal_grid_size+minimal_grid_size, y_shape)\n",
    "                            c_0 = xstart + c*minimal_grid_size\n",
    "                            c_1 = xstart + min(c*minimal_grid_size+minimal_grid_size, x_shape)\n",
    "                            #print(r, c, r_0, r_1, c_0, c_1)\n",
    "\n",
    "                            ### only process a small part of the whole subregion\n",
    "                            #im = np.copy(rgb_rb[ystart:ystop, xstart:xstop, :])\n",
    "                            im = np.copy(rgb_rb[r_0:r_1, c_0:c_1, :])\n",
    "                            image = im.reshape(im.shape[0],im.shape[1],1,3)\n",
    "\n",
    "                            # Create color container \n",
    "                            colors_container = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "                            for i,color in enumerate(color_avg):\n",
    "                                colors_container[:,:,i,:] = color\n",
    "                            colors_container2 = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg2),3])\n",
    "                            for i,color in enumerate(color_avg2):\n",
    "                                colors_container2[:,:,i,:] = color\n",
    "                            \n",
    "                            rgb_weight = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                            rgb_weight[:,:,:,0] = 1 # 2\n",
    "                            rgb_weight[:,:,:,1] = 1 # 4\n",
    "                            rgb_weight[:,:,:,2] = 1 # 3\n",
    "\n",
    "                            background_correction_direct_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                            background_correction_direct_rgb[:,:,:,0] = 1.0\n",
    "                            background_correction_direct_rgb[:,:,:,1] = 1.0\n",
    "                            background_correction_direct_rgb[:,:,:,2] = 1.0\n",
    "\n",
    "                            image_deviation = np.zeros(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                            image_deviation[:,:,:,0] = image[:,:,:,0] - image[:,:,:,1]\n",
    "                            image_deviation[:,:,:,1] = image[:,:,:,0] - image[:,:,:,2]\n",
    "                            image_deviation[:,:,:,2] = image[:,:,:,1] - image[:,:,:,2]\n",
    "\n",
    "                            legend_deviation = np.zeros(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "                            legend_deviation[:,:,:,0] = colors_container[:,:,:,0] - colors_container[:,:,:,1]\n",
    "                            legend_deviation[:,:,:,1] = colors_container[:,:,:,0] - colors_container[:,:,:,2]\n",
    "                            legend_deviation[:,:,:,2] = colors_container[:,:,:,1] - colors_container[:,:,:,2]\n",
    "                            \n",
    "                            background_correction_deviated_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                            background_correction_deviated_rgb[:,:,:,:] = 0.5 + 0.5*(1.0-abs(image_deviation[:,:,:,:])/255.0)\n",
    "\n",
    "\n",
    "                            def closest(image,color_container):\n",
    "                                shape = image.shape[:2]\n",
    "                                total_shape = shape[0]*shape[1]\n",
    "\n",
    "                                # calculate distances\n",
    "                                distances_0 = np.sqrt(np.sum(rgb_weight*((color_container*background_correction_direct_rgb-image)**2),axis=3))\n",
    "                                distances_1 = np.sqrt(np.sum(((legend_deviation*background_correction_deviated_rgb-image_deviation)**2),axis=3))\n",
    "                                distances = distances_0*0.95 + distances_1*0.05\n",
    "\n",
    "                                # in the 1st version, the distance is the distance to the color of each key\n",
    "                                # in the 2nd version, the distance is the distance to the color under the color set of each key\n",
    "\n",
    "                                #print(distances.shape) # shape: (1500, 1500, # of colors)\n",
    "                                #print(mapping_color_set_to_color_prob_tp.shape) # shape: (# of colors, # of keys)\n",
    "\n",
    "                                multiplied_distances = np.dot(distances, mapping_color_set_to_color_prob_tp)\n",
    "\n",
    "                                #print(multiplied_distances.shape) # shape: (1500, 1500, # of keys)\n",
    "                                \n",
    "                                conv_distances = scipy.ndimage.convolve(multiplied_distances, distance_kernel)\n",
    "\n",
    "\n",
    "                                min_index_map = np.argmin(conv_distances, axis=2)\n",
    "                                min_index = min_index_map.reshape(-1)\n",
    "                                natural_index = np.arange(total_shape)\n",
    "\n",
    "                                reshaped_container = colors_container2.reshape(-1,len(color_avg2),3) # only use one color to re-color the map\n",
    "\n",
    "                                color_view = reshaped_container[natural_index, min_index].reshape(shape[0], shape[1], 3)\n",
    "                                return color_view, min_index_map\n",
    "                            \n",
    "                            \n",
    "                            result_image, min_index_map = closest(image, colors_container)\n",
    "                            result_image = result_image.astype(np.uint8)\n",
    "                            min_index_map = min_index_map.astype(np.uint8)\n",
    "\n",
    "                            grid_completed += 1\n",
    "                            print('processing _v0 >>> _v1 (finding the closest color)... (grid completed '+str(grid_completed)+'/'+str(grid_counting)+')... :', datetime.now()-runningtime_start)\n",
    "\n",
    "                            #plt.imshow(result_image)\n",
    "                            #plt.show()\n",
    "\n",
    "                            #Image.fromarray(result_image.astype(np.uint8)).show()\n",
    "\n",
    "\n",
    "                            #subtract_rgb = []\n",
    "\n",
    "                            #repaste_image[ystart:ystop, xstart:xstop, :] = np.copy(result_image[:, :, :])\n",
    "                            repaste_image[r_0:r_1, c_0:c_1, :] = np.copy(result_image[:, :, :])\n",
    "                            repaste_index[r_0:r_1, c_0:c_1, 0] = np.copy(min_index_map[:, :])\n",
    "                else:\n",
    "                    im = np.copy(rgb_rb[ystart:ystop, xstart:xstop, :])\n",
    "                    image = im.reshape(im.shape[0],im.shape[1],1,3)\n",
    "\n",
    "                    # Create color container \n",
    "                    colors_container = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "                    for i,color in enumerate(color_avg):\n",
    "                        colors_container[:,:,i,:] = color\n",
    "                    colors_container2 = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg2),3])\n",
    "                    for i,color in enumerate(color_avg2):\n",
    "                        colors_container2[:,:,i,:] = color\n",
    "                    \n",
    "                    rgb_weight = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                    rgb_weight[:,:,:,0] = 1 # 2\n",
    "                    rgb_weight[:,:,:,1] = 1 # 4\n",
    "                    rgb_weight[:,:,:,2] = 1 # 3\n",
    "\n",
    "                    background_correction_direct_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                    background_correction_direct_rgb[:,:,:,0] = 1.0\n",
    "                    background_correction_direct_rgb[:,:,:,1] = 1.0\n",
    "                    background_correction_direct_rgb[:,:,:,2] = 1.0\n",
    "\n",
    "                    image_deviation = np.zeros(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                    image_deviation[:,:,:,0] = image[:,:,:,0] - image[:,:,:,1]\n",
    "                    image_deviation[:,:,:,1] = image[:,:,:,0] - image[:,:,:,2]\n",
    "                    image_deviation[:,:,:,2] = image[:,:,:,1] - image[:,:,:,2]\n",
    "\n",
    "                    legend_deviation = np.zeros(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "                    legend_deviation[:,:,:,0] = colors_container[:,:,:,0] - colors_container[:,:,:,1]\n",
    "                    legend_deviation[:,:,:,1] = colors_container[:,:,:,0] - colors_container[:,:,:,2]\n",
    "                    legend_deviation[:,:,:,2] = colors_container[:,:,:,1] - colors_container[:,:,:,2]\n",
    "                    \n",
    "                    background_correction_deviated_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "                    background_correction_deviated_rgb[:,:,:,:] = 0.5 + 0.5*(1.0-abs(image_deviation[:,:,:,:])/255.0)\n",
    "\n",
    "                    print('processing _v0 >>> _v1 (finding the closest color)... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "                    def closest(image,color_container):\n",
    "                        shape = image.shape[:2]\n",
    "                        total_shape = shape[0]*shape[1]\n",
    "\n",
    "                        # calculate distances\n",
    "                        distances_0 = np.sqrt(np.sum(rgb_weight*((color_container*background_correction_direct_rgb-image)**2),axis=3))\n",
    "                        distances_1 = np.sqrt(np.sum(((legend_deviation*background_correction_deviated_rgb-image_deviation)**2),axis=3))\n",
    "                        distances = distances_0*0.95 + distances_1*0.05\n",
    "\n",
    "                        # in the 1st version, the distance is the distance to the color of each key\n",
    "                        # in the 2nd version, the distance is the distance to the color under the color set of each key\n",
    "\n",
    "                        #print(distances.shape) # shape: (1000, 1000, # of colors)\n",
    "                        #print(mapping_color_set_to_color_prob_tp.shape) # shape: (# of colors, # of keys)\n",
    "\n",
    "                        multiplied_distances = np.dot(distances, mapping_color_set_to_color_prob_tp)\n",
    "\n",
    "                        conv_distances = scipy.ndimage.convolve(multiplied_distances, distance_kernel)\n",
    "\n",
    "                        min_index_map = np.argmin(conv_distances, axis=2)\n",
    "                        min_index = min_index_map.reshape(-1)\n",
    "                        natural_index = np.arange(total_shape)\n",
    "\n",
    "                        reshaped_container = colors_container2.reshape(-1,len(color_avg2),3) # only use one color to re-color the map\n",
    "\n",
    "                        color_view = reshaped_container[natural_index, min_index].reshape(shape[0], shape[1], 3)\n",
    "                        return color_view, min_index_map\n",
    "                    \n",
    "                    result_image, min_index_map = closest(image, colors_container)\n",
    "                    result_image = result_image.astype(np.uint8)\n",
    "                    min_index_map = min_index_map.astype(np.uint8)\n",
    "\n",
    "                    #plt.imshow(result_image)\n",
    "                    #plt.show()\n",
    "\n",
    "                    #Image.fromarray(result_image.astype(np.uint8)).show()\n",
    "\n",
    "\n",
    "                    #subtract_rgb = []\n",
    "\n",
    "                    repaste_image = np.zeros((img_bound.shape[0], img_bound.shape[1], 3), dtype='uint8')\n",
    "                    repaste_image[ystart:ystop, xstart:xstop, :] = np.copy(result_image[:, :, :])\n",
    "\n",
    "                    repaste_index = np.zeros((img_bound.shape[0], img_bound.shape[1], 1), dtype='uint8')\n",
    "                    repaste_index[ystart:ystop, xstart:xstop, 0] = np.copy(min_index_map[:, :])\n",
    "\n",
    "                        \n",
    "                \n",
    "                # print('processing _v1 >>> _v2 (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "                #result_image0 = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "                #out_file_path0=solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring_attempt_0.png'\n",
    "                #cv2.imwrite(out_file_path0, result_image0)\n",
    "\n",
    "                repaste_image = cv2.cvtColor(repaste_image, cv2.COLOR_RGB2BGR)\n",
    "                out_file_path0=solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring_attempt_1.png'\n",
    "                cv2.imwrite(out_file_path0, repaste_image)\n",
    "\n",
    "                out_file_path0=solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring_index_1.png'\n",
    "                cv2.imwrite(out_file_path0, repaste_index)\n",
    "\n",
    "                repaste_image = cv2.cvtColor(repaste_image, cv2.COLOR_BGR2RGB)\n",
    "                repaste_image_v2 = np.copy(repaste_image)\n",
    "                if check_ocean == False:\n",
    "                    # if we manually add the ocean color\n",
    "                    ocean_mask = cv2.inRange(repaste_image, np.array([218, 240, 254]), np.array([218, 240, 254]))\n",
    "                    repaste_image_v2 = cv2.bitwise_and(repaste_image, repaste_image, mask=(255-ocean_mask))\n",
    "                    #repaste_image_v2[targeted_image == np.array([218, 240, 254])] = np.array([0,0,0])\n",
    "                \n",
    "                repaste_image_v2 = cv2.cvtColor(repaste_image_v2, cv2.COLOR_RGB2BGR)\n",
    "                out_file_path0=solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring_attempt_2.png'\n",
    "                cv2.imwrite(out_file_path0, repaste_image_v2)\n",
    "\n",
    "                \n",
    "                #targeted_image = cv2.imread(out_file_path0)\n",
    "                #color_thief = ColorThief(out_file_path0)\n",
    "                \n",
    "                # get the dominant color\n",
    "                #dominant_color = color_thief.get_color(quality=1)\n",
    "                #palette = color_thief.get_palette(color_count=10)\n",
    "\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "                #print(dominant_color)\n",
    "                #print(palette)\n",
    "                if os.path.isfile(solutiona_dir+'intermediate8/'+'running_time_record_v3.csv') == False:\n",
    "                    with open(solutiona_dir+'intermediate8/'+'running_time_record_v3.csv','w') as fd:\n",
    "                        fd.write('File,checkpoint_0,checkpoint_1\\n')\n",
    "                        fd.close()\n",
    "                with open(solutiona_dir+'intermediate8/'+'running_time_record_v3.csv','a') as fd:\n",
    "                    fd.write(map_name+',')\n",
    "                    for rtc in range(0, len(running_time_v)):\n",
    "                        fd.write(str(running_time_v[rtc])+',')\n",
    "                    fd.write('\\n')\n",
    "                    fd.close()\n",
    "\n",
    "\n",
    "\n",
    "else:\n",
    "    print('Not applying recoloring...')\n",
    "\n",
    "# 603m 18.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfe4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preprocessing_recoloring == True:\n",
    "    print('Applying recoloring...')\n",
    "\n",
    "    #data_dir='validation'\n",
    "    if not os.path.exists(solutiona_dir+str('intermediate8(2)/')):\n",
    "        os.makedirs(solutiona_dir+str('intermediate8(2)/'))\n",
    "    \n",
    "    for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "    #for target_file_q in range(len(candidate_file_name_for_polygon)-1, 0, -1):\n",
    "    #for target_file_q in range(4, 5, 1):\n",
    "        file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "        running_time_v = []\n",
    "        \n",
    "        \n",
    "        # get the .tif files\n",
    "        if '.json' in file_name:\n",
    "            runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "            filename=file_name.replace('.json', '.tif')\n",
    "            print('Working on map:', file_name)\n",
    "            file_path=os.path.join(data_dir, filename)\n",
    "            test_json=file_path.replace('.tif', '.json')\n",
    "            file_name_json = test_json.replace('.json', '.json')\n",
    "            \n",
    "            #print(test_json)\n",
    "            img000 = cv2.imread(file_path)\n",
    "            #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "            #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "            img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "            img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "            img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "            img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "            img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "            img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "            img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "            with open(file_name_json) as f:\n",
    "                gj = json.load(f)\n",
    "            json_height = gj['imageHeight']\n",
    "            json_width = gj['imageWidth']\n",
    "            rescale_factor_0 = 1.0\n",
    "            rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "            ## Non-white background\n",
    "            non_white_background = False\n",
    "            if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "                lower_white = np.array([250,250,250])\n",
    "                upper_white = np.array([256,256,256])\n",
    "                mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                lower_white = np.array([0,0,0])\n",
    "                upper_white = np.array([130,130,130])\n",
    "                mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "                mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "                corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "                corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "                if corner_avg_white / corner_area < 0.66:\n",
    "                    non_white_background = True\n",
    "                    print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            ### Legend is always not considered\n",
    "            if True:\n",
    "                for this_gj in gj['shapes']:\n",
    "                    #print(this_gj)\n",
    "                    names = this_gj['label']\n",
    "                    features = this_gj['points']\n",
    "\n",
    "                    geoms = np.array(features)\n",
    "                    y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                    x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                    x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                    legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                    legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                    img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "                img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "                img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "                img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "                img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "            hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "            rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "            hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "            rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            poly_counter = 0\n",
    "            #color_space = []\n",
    "            color_avg = []\n",
    "            color_avg2 = []\n",
    "            color_set_avg = []\n",
    "            map_name = file_name.replace('.json', '')\n",
    "            legend_name = []\n",
    "            legend_name_check = []\n",
    "            extracted_legend_name = []\n",
    "\n",
    "\n",
    "            hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "            rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "            if not os.path.exists(solutiona_dir+str('intermediate8(2)/')+str(map_name)+'/'):\n",
    "                os.makedirs(solutiona_dir+str('intermediate8(2)/')+str(map_name)+'/')\n",
    "\n",
    "\n",
    "            for this_gj in gj['shapes']:\n",
    "                #if '_poly' not in names:\n",
    "                    #continue\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "                \n",
    "                if '_poly' not in names:\n",
    "                    continue\n",
    "                if names in legend_name_check:\n",
    "                    continue\n",
    "\n",
    "\n",
    "                legend_name_check.append(names)\n",
    "                legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "                poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "\n",
    "            #print('time checkpoint _v0:', datetime.now()-runningtime_start)\n",
    "            #running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "            ans_category = np.zeros((poly_counter+1, img_rb.shape[0], img_rb.shape[1]), dtype='uint8')\n",
    "\n",
    "            blank = np.ones((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)*255\n",
    "            ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "            #print(legend_name)\n",
    "            #print(color_space)\n",
    "\n",
    "            bgr_image = cv2.imread(solutiona_dir+'intermediate8/'+map_name+'_polygon_recoloring_index_1.png')\n",
    "            #print(bgr_image[:,:,0].shape)\n",
    "\n",
    "            temp_rgb_recoloring = bgr_image[:,:,0]\n",
    "            temp_rgb_recoloring = temp_rgb_recoloring.flatten()\n",
    "            #temp_rgb_recoloring2 = np.zeros(shape=(temp_rgb_recoloring.shape[0], 3),dtype=np.uint8)\n",
    "            #print(temp_rgb_recoloring.shape)\n",
    "            #print(temp_rgb_recoloring2.shape)\n",
    "\n",
    "            for color_index in range(0, poly_counter):\n",
    "                #temp_rgb_recoloring2[temp_rgb_recoloring == color_index] = color_avg2[color_index]\n",
    "\n",
    "                temp_rgb_recoloring3 = np.zeros(shape=(temp_rgb_recoloring.shape[0], 1),dtype=np.uint8)\n",
    "                temp_rgb_recoloring3[temp_rgb_recoloring == color_index] = 255\n",
    "\n",
    "                temp_rgb_recoloring3 = np.reshape(temp_rgb_recoloring3, (-1, bgr_image.shape[1], 1))\n",
    "                temp_rgb_recoloring3 = cv2.bitwise_and(temp_rgb_recoloring3, img_bound)\n",
    "                out_file_path0 = os.path.join(solutiona_dir+'intermediate8(2)', map_name, map_name+'_'+legend_name[color_index]+'_poly_rc_v0.png')\n",
    "                cv2.imwrite(out_file_path0, temp_rgb_recoloring3)\n",
    "\n",
    "\n",
    "            #temp_rgb_recoloring2 = np.reshape(temp_rgb_recoloring2, (-1, bgr_image.shape[1], 3))\n",
    "            \n",
    "            #print(temp_rgb_recoloring.shape)\n",
    "            #temp_rgb_recoloring2 = cv2.cvtColor(temp_rgb_recoloring2, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# 12m 57.8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69657b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0556434b",
   "metadata": {},
   "source": [
    "### Polygon extraction for intermediate bitmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ec7d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_dir='validation'\n",
    "if not os.path.exists(solutiona_dir+str('intermediate7(2)/')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate7(2)/'))\n",
    "if not os.path.exists(solutiona_dir+str('intermediate7(2)/Output/')):\n",
    "    os.makedirs(solutiona_dir+str('intermediate7(2)/Output/'))\n",
    "\n",
    "#for target_file_q in range(0, len(candidate_file_name_for_polygon), 1):\n",
    "for target_file_q in range(10, 9, -1):\n",
    "#for target_file_q in range(4, 5, 1):\n",
    "    file_name = candidate_file_name_for_polygon[target_file_q]\n",
    "    running_time_v = []\n",
    "\n",
    "    if 'TX_Driftwood_Wimberley' not in file_name:\n",
    "        break\n",
    "    \n",
    "    # get the .tif files\n",
    "    if '.json' in file_name:\n",
    "        runningtime_start=datetime.now()\n",
    "\n",
    "\n",
    "        filename=file_name.replace('.json', '.tif')\n",
    "        print('Working on map:', file_name)\n",
    "        file_path=os.path.join(data_dir, filename)\n",
    "        test_json=file_path.replace('.tif', '.json')\n",
    "        file_name_json = test_json.replace('.json', '.json')\n",
    "        \n",
    "        #print(test_json)\n",
    "        img000 = cv2.imread(file_path)\n",
    "        #hsv0 = cv2.cvtColor(img0, cv2.COLOR_BGR2HSV)\n",
    "        #rgb0 = cv2.cvtColor(img0, cv2.COLOR_BGR2RGB)\n",
    "        img_bound = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_expected_crop_region.tif')\n",
    "        img_bound = cv2.cvtColor(img_bound, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_crop_gray = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_grayregion.png')\n",
    "        img_crop_black = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_crop_blackregion.png')\n",
    "        img_crop_gray = cv2.cvtColor(img_crop_gray, cv2.COLOR_BGR2GRAY)\n",
    "        img_crop_black = cv2.cvtColor(img_crop_black, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #img_boundary = cv2.imread(solutiona_dir+'intermediate5/Extraction/'+file_name.replace('.json', '')+'_overall_boundary.png')\n",
    "        img_boundary = cv2.imread(solutiona_dir+'intermediate5/Extraction(3)/'+file_name.replace('.json', '')+'_overall_boundary_candidate.png')\n",
    "        img_boundary = cv2.cvtColor(img_boundary, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img_rb = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black.png')\n",
    "        img_ms = cv2.imread(solutiona_dir+'intermediate7/'+file_name.replace('.json', '')+'_remove_black_mean_shift.png')\n",
    "\n",
    "\n",
    "        with open(file_name_json) as f:\n",
    "            gj = json.load(f)\n",
    "        json_height = gj['imageHeight']\n",
    "        json_width = gj['imageWidth']\n",
    "        rescale_factor_0 = 1.0\n",
    "        rescale_factor_1 = 1.0\n",
    "\n",
    "\n",
    "\n",
    "        ## Non-white background\n",
    "        non_white_background = False\n",
    "        if np.sum(img_bound) / 255 >= (img_bound.shape[0]*img_bound.shape[1]) * 0.99 or np.unique(img_bound).shape[0] == 1:\n",
    "            lower_white = np.array([250,250,250])\n",
    "            upper_white = np.array([256,256,256])\n",
    "            mask_white_img000 = cv2.inRange(img000, lower_white, upper_white)\n",
    "            lower_white = np.array([0,0,0])\n",
    "            upper_white = np.array([130,130,130])\n",
    "            mask_white_img000_2 = cv2.inRange(img000, lower_white, upper_white)\n",
    "            mask_white_img000 = cv2.bitwise_or(mask_white_img000, mask_white_img000_2)\n",
    "\n",
    "            corner_avg_white = np.sum(mask_white_img000[int(mask_white_img000.shape[0]*98/100): int(mask_white_img000.shape[0]*99/100), int(mask_white_img000.shape[1]*98/100): int(mask_white_img000.shape[1]*99/100)])/255.0\n",
    "            corner_area = (int(mask_white_img000.shape[0]*99/100) - int(mask_white_img000.shape[0]*98/100)) * (int(mask_white_img000.shape[1]*99/100) - int(mask_white_img000.shape[1]*98/100))\n",
    "\n",
    "            if corner_avg_white / corner_area < 0.66:\n",
    "                non_white_background = True\n",
    "                print('non_white_background')\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        ### Legend is always not considered\n",
    "        if True:\n",
    "            for this_gj in gj['shapes']:\n",
    "                #print(this_gj)\n",
    "                names = this_gj['label']\n",
    "                features = this_gj['points']\n",
    "\n",
    "                geoms = np.array(features)\n",
    "                y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "                x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "                x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "                legend_mask = np.ones((img_rb.shape[0], img_rb.shape[1]), dtype='uint8') *255\n",
    "                legend_mask[x_min:x_max, y_min:y_max] = 0\n",
    "                img_bound = cv2.bitwise_and(img_bound, legend_mask)\n",
    "            img_rb = cv2.bitwise_and(img_rb, img_rb, mask=img_bound)\n",
    "            img_ms = cv2.bitwise_and(img_ms, img_ms, mask=img_bound)\n",
    "            img_crop_gray = cv2.bitwise_and(img_crop_gray, img_crop_gray, mask=img_bound)\n",
    "            img_crop_black = cv2.bitwise_and(img_crop_black, img_crop_black, mask=img_bound)\n",
    "        hsv_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2HSV)\n",
    "        rgb_rb = cv2.cvtColor(img_rb, cv2.COLOR_BGR2RGB)\n",
    "        hsv_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2HSV)\n",
    "        rgb_ms = cv2.cvtColor(img_ms, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        poly_counter = 0\n",
    "        color_space = []\n",
    "        color_avg = []\n",
    "        color_avg2 = []\n",
    "        map_name = file_name.replace('.json', '')\n",
    "        legend_name = []\n",
    "        legend_name_check = []\n",
    "        extracted_legend_name = []\n",
    "\n",
    "\n",
    "        hsv_space = np.zeros((255), dtype='uint8') # only for h space\n",
    "        rgb_space = np.zeros((255,255,3), dtype='uint8')\n",
    "\n",
    "\n",
    "        if not os.path.exists(solutiona_dir+'intermediate7(2)/'+map_name):\n",
    "            os.makedirs(solutiona_dir+'intermediate7(2)/'+map_name)\n",
    "\n",
    "\n",
    "\n",
    "        for this_gj in gj['shapes']:\n",
    "            #if '_poly' not in names:\n",
    "                #continue\n",
    "            #print(this_gj)\n",
    "            names = this_gj['label']\n",
    "            features = this_gj['points']\n",
    "            \n",
    "            if '_poly' not in names:\n",
    "                continue\n",
    "            if names in legend_name_check:\n",
    "                continue\n",
    "\n",
    "\n",
    "            legend_name_check.append(names)\n",
    "            legend_name.append(names.replace('_poly',''))\n",
    "\n",
    "            poly_counter = poly_counter+1\n",
    "\n",
    "\n",
    "            ### There is no groundtruth for validation data\n",
    "            #print('training/'+map_name+'_'+names+'.tif')\n",
    "\n",
    "\n",
    "            ### Read json source for the legend\n",
    "            geoms = np.array(features)\n",
    "            y_min = int(np.min(geoms, axis=0)[0]*rescale_factor_1)\n",
    "            y_max = int(np.max(geoms, axis=0)[0]*rescale_factor_1)\n",
    "            x_min = int(np.min(geoms, axis=0)[1]*rescale_factor_0)\n",
    "            x_max = int(np.max(geoms, axis=0)[1]*rescale_factor_0)\n",
    "\n",
    "            img_legend = np.zeros((x_max-x_min, y_max-y_min, 3), dtype='uint8')\n",
    "            img_legend = np.copy(img000[x_min:x_max, y_min:y_max, :])\n",
    "            \n",
    "            if print_intermediate_image == True:\n",
    "                out_file_path0=solutiona_dir+'intermediate7(2)/'+map_name+'/'+map_name+'_'+names+'_legend.tif'\n",
    "                cv2.imwrite(out_file_path0, img_legend)\n",
    "            \n",
    "            \n",
    "            img_legend = cv2.cvtColor(img_legend, cv2.COLOR_BGR2RGB)\n",
    "            img_legend = img_legend[int(img_legend.shape[0]/8):int(img_legend.shape[0]*7/8), int(img_legend.shape[1]/8):int(img_legend.shape[1]*7/8), :]\n",
    "            hsv_legend = cv2.cvtColor(img_legend, cv2.COLOR_RGB2HSV)\n",
    "            black_threshold = 30 #130\n",
    "            white_threshold = 250 #245\n",
    "\n",
    "            lower_black_rgb_trimmed0 = np.array([0,0,0])\n",
    "            upper_black_rgb_trimmed0 = np.array([130,130,130])\n",
    "            mask_test_img_legend = cv2.inRange(img_legend, lower_black_rgb_trimmed0, upper_black_rgb_trimmed0)\n",
    "            if np.sum(mask_test_img_legend == 255) > np.sum(img_legend > 0) * 0.25:\n",
    "                black_threshold = 30\n",
    "            \n",
    "            rgb_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "            hsv_trimmed = np.zeros((img_legend.shape[2], img_legend.shape[0], img_legend.shape[1]), dtype='uint8')\n",
    "            rgb_trimmed = rgb_trimmed.astype(float)\n",
    "            hsv_trimmed = hsv_trimmed.astype(float)\n",
    "            for dimension in range(0, 3):\n",
    "                rgb_trimmed[dimension] = np.copy(img_legend[:,:,dimension]).astype(float)\n",
    "                hsv_trimmed[dimension] = np.copy(hsv_legend[:,:,dimension]).astype(float)\n",
    "\n",
    "            rgb_trimmed_temp = np.copy(rgb_trimmed)\n",
    "            rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "            hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]<=black_threshold, rgb_trimmed_temp[1]<=black_threshold, rgb_trimmed_temp[2]<=black_threshold])] = np.nan\n",
    "\n",
    "            rgb_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[0, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            rgb_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[1, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            rgb_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "            hsv_trimmed[2, np.logical_and.reduce([rgb_trimmed_temp[0]>=white_threshold, rgb_trimmed_temp[1]>=white_threshold, rgb_trimmed_temp[2]>=white_threshold])] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "            if np.sum(np.isnan(hsv_trimmed)) >= (hsv_trimmed.shape[0]*hsv_trimmed.shape[1]*hsv_trimmed.shape[2]):\n",
    "                color_space_holder = []\n",
    "                rgb_lower_box = np.array((0,0,0), dtype='uint8')\n",
    "                rgb_upper_box = np.array((0,0,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array((245,245,245), dtype='uint8')\n",
    "                rgb_upper_box = np.array((255,255,255), dtype='uint8')\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                color_avg_holder = np.array((0,0,0), dtype='uint8')\n",
    "                color_avg_holder2 = np.array((0,0,0), dtype='uint8')\n",
    "            else:\n",
    "                color_space_holder = []\n",
    "                hsv_lower_box = np.array([int(np.nanquantile(hsv_trimmed[0],.2)),int(np.nanquantile(hsv_trimmed[1],.1)),int(np.nanquantile(hsv_trimmed[2],.1))]) #.2\n",
    "                hsv_upper_box = np.array([int(np.nanquantile(hsv_trimmed[0],.8)),int(np.nanquantile(hsv_trimmed[1],.9)),int(np.nanquantile(hsv_trimmed[2],.9))]) #.8\n",
    "                color_space_holder.append(hsv_lower_box)\n",
    "                color_space_holder.append(hsv_upper_box)\n",
    "                hsv_space[int(np.nanquantile(hsv_trimmed[0],.2)): int(np.nanquantile(hsv_trimmed[0],.8))] += poly_counter\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.2)),int(np.nanquantile(rgb_trimmed[1],.2)),int(np.nanquantile(rgb_trimmed[2],.2))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.8)),int(np.nanquantile(rgb_trimmed[1],.8)),int(np.nanquantile(rgb_trimmed[2],.8))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_space[int(np.nanquantile(rgb_trimmed[0],.3)): int(np.nanquantile(rgb_trimmed[0],.7)), int(np.nanquantile(rgb_trimmed[1],.3)): int(np.nanquantile(rgb_trimmed[1],.7)), int(np.nanquantile(rgb_trimmed[2],.3)): int(np.nanquantile(rgb_trimmed[2],.7))] = poly_counter\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.1)),int(np.nanquantile(rgb_trimmed[1],.1)),int(np.nanquantile(rgb_trimmed[2],.1))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.9)),int(np.nanquantile(rgb_trimmed[1],.9)),int(np.nanquantile(rgb_trimmed[2],.9))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.05)),int(np.nanquantile(rgb_trimmed[1],.05)),int(np.nanquantile(rgb_trimmed[2],.05))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.95)),int(np.nanquantile(rgb_trimmed[1],.95)),int(np.nanquantile(rgb_trimmed[2],.95))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.03)),int(np.nanquantile(rgb_trimmed[1],.03)),int(np.nanquantile(rgb_trimmed[2],.03))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.97)),int(np.nanquantile(rgb_trimmed[1],.97)),int(np.nanquantile(rgb_trimmed[2],.97))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.02)),int(np.nanquantile(rgb_trimmed[1],.02)),int(np.nanquantile(rgb_trimmed[2],.02))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.98)),int(np.nanquantile(rgb_trimmed[1],.98)),int(np.nanquantile(rgb_trimmed[2],.98))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "                rgb_lower_box = np.array([int(np.nanquantile(rgb_trimmed[0],.01)),int(np.nanquantile(rgb_trimmed[1],.01)),int(np.nanquantile(rgb_trimmed[2],.01))])\n",
    "                rgb_upper_box = np.array([int(np.nanquantile(rgb_trimmed[0],.99)),int(np.nanquantile(rgb_trimmed[1],.99)),int(np.nanquantile(rgb_trimmed[2],.99))])\n",
    "                color_space_holder.append(rgb_lower_box)\n",
    "                color_space_holder.append(rgb_upper_box)\n",
    "\n",
    "                color_avg_holder = np.array([int(np.nanquantile(rgb_trimmed[0],.5)),int(np.nanquantile(rgb_trimmed[1],.5)),int(np.nanquantile(rgb_trimmed[2],.5))])\n",
    "                color_avg_holder2 = np.array([int(np.nanquantile(hsv_trimmed[0],.5)),int(np.nanquantile(hsv_trimmed[1],.5)),int(np.nanquantile(hsv_trimmed[2],.5))])\n",
    "\n",
    "            color_space.append(color_space_holder)\n",
    "            color_avg.append(color_avg_holder)\n",
    "            color_avg2.append(color_avg_holder2)\n",
    "\n",
    "        print('time checkpoint _v0:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "        ans_category = np.zeros((poly_counter+1, img_rb.shape[0], img_rb.shape[1]), dtype='uint8')\n",
    "\n",
    "        blank = np.ones((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)*255\n",
    "        ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Some preprocessing for basemap to support further text detection and polygon separation\n",
    "        color_dif_counter = 0\n",
    "        if split_multiprocessing == True:\n",
    "            with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                callback = pool.starmap_async(extraction_step0_color_difference_worker.extraction_step0_color_difference_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, img_bound, rgb_rb, hsv_rb, color_avg[this_poly], color_avg2[this_poly], color_space[this_poly], ) for this_poly in range(0, poly_counter)])\n",
    "                multiprocessing_results = callback.get()\n",
    "\n",
    "                for legend, rec in multiprocessing_results:\n",
    "                    if rec == True:\n",
    "                        color_dif_counter = color_dif_counter + 1\n",
    "        print('time checkpoint _v1:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        # If there is color shift for all legends, but this section is never used for the final solution. (smoothing_map always set to False)\n",
    "        if smoothing_map == True:\n",
    "            color_avg.append(np.array([0,0,0]))\n",
    "            #color_avg.append(np.array([255,255,255]))\n",
    "\n",
    "            img_bound_argwhere = np.argwhere(img_bound)\n",
    "            (ystart, xstart), (ystop, xstop) = img_bound_argwhere.min(0), img_bound_argwhere.max(0) + 1 \n",
    "            im = np.copy(rgb_rb[ystart:ystop, xstart:xstop, :])\n",
    "            image = im.reshape(im.shape[0],im.shape[1],1,3)\n",
    "\n",
    "            # Create color container \n",
    "            colors_container = np.ones(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "            for i,color in enumerate(color_avg):\n",
    "                colors_container[:,:,i,:] = color\n",
    "            \n",
    "            rgb_weight = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            rgb_weight[:,:,:,0] = 1 # 2\n",
    "            rgb_weight[:,:,:,1] = 1 # 4\n",
    "            rgb_weight[:,:,:,2] = 1 # 3\n",
    "\n",
    "            background_correction_direct_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            background_correction_direct_rgb[:,:,:,0] = 0.9\n",
    "            background_correction_direct_rgb[:,:,:,1] = 0.9\n",
    "            background_correction_direct_rgb[:,:,:,2] = 0.9\n",
    "\n",
    "            image_deviation = np.zeros(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            image_deviation[:,:,:,0] = image[:,:,:,0] - image[:,:,:,1]\n",
    "            image_deviation[:,:,:,1] = image[:,:,:,0] - image[:,:,:,2]\n",
    "            image_deviation[:,:,:,2] = image[:,:,:,1] - image[:,:,:,2]\n",
    "\n",
    "            legend_deviation = np.zeros(shape=[image.shape[0],image.shape[1],len(color_avg),3])\n",
    "            legend_deviation[:,:,:,0] = colors_container[:,:,:,0] - colors_container[:,:,:,1]\n",
    "            legend_deviation[:,:,:,1] = colors_container[:,:,:,0] - colors_container[:,:,:,2]\n",
    "            legend_deviation[:,:,:,2] = colors_container[:,:,:,1] - colors_container[:,:,:,2]\n",
    "            \n",
    "            background_correction_deviated_rgb = np.ones(shape=[image.shape[0],image.shape[1],1,3])\n",
    "            background_correction_deviated_rgb[:,:,:,:] = 0.5 + 0.5*(1.0-abs(image_deviation[:,:,:,:])/255.0)\n",
    "\n",
    "            print('processing _v0 >>> _v1 (finding the closest color)... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "            def closest(image,color_container):\n",
    "                shape = image.shape[:2]\n",
    "                total_shape = shape[0]*shape[1]\n",
    "\n",
    "                # calculate distances\n",
    "                distances_0 = np.sqrt(np.sum(rgb_weight*((color_container*background_correction_direct_rgb-image)**2),axis=3))\n",
    "                distances_1 = np.sqrt(np.sum(((legend_deviation*background_correction_deviated_rgb-image_deviation)**2),axis=3))\n",
    "                distances = distances_0*0.9 + distances_1*0.1\n",
    "\n",
    "                min_index = np.argmin(distances,axis=2).reshape(-1)\n",
    "                natural_index = np.arange(total_shape)\n",
    "\n",
    "                reshaped_container = colors_container.reshape(-1,len(color_avg),3)\n",
    "\n",
    "                color_view = reshaped_container[natural_index,min_index].reshape(shape[0],shape[1],3)\n",
    "                return color_view, distances\n",
    "            \n",
    "            result_image, distances = closest(image,colors_container)\n",
    "            result_image = result_image.astype(np.uint8)\n",
    "\n",
    "            #plt.imshow(result_image)\n",
    "            #plt.show()\n",
    "\n",
    "            #Image.fromarray(result_image.astype(np.uint8)).show()\n",
    "\n",
    "\n",
    "            #subtract_rgb = []\n",
    "\n",
    "            \n",
    "            # multiprocessing_step1\n",
    "            with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                callback = pool.starmap_async(extraction_step1_worker.extraction_step1_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, rgb_ms, result_image, distances[:,:,this_poly], len(color_avg), color_avg[this_poly], poly_counter, np.sum(img_bound), image.shape, im, ) for this_poly in range(0, poly_counter)])\n",
    "                multiprocessing_results = callback.get()\n",
    "\n",
    "                for legend, img_masked, this_subtract_rgb in multiprocessing_results:\n",
    "                    # add masked result into private ans_category\n",
    "                    ans_category[legend] = np.copy(img_masked)\n",
    "                    # add mophological result into global ans_category\n",
    "                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                    img_masked_morphology = cv2.morphologyEx(img_masked, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                    img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                    ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "                    \n",
    "                    for space in range(2, len(color_space[legend]), 2):\n",
    "                        color_space[legend][space] = color_space[legend][space] - this_subtract_rgb\n",
    "                        color_space[legend][space+1] = color_space[legend][space+1] - this_subtract_rgb + 1\n",
    "                    \n",
    "            \n",
    "            print('processing _v1 >>> _v2 (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "            result_image0 = cv2.cvtColor(result_image, cv2.COLOR_RGB2BGR)\n",
    "            out_file_path0=solutiona_dir+'intermediate7(2)/'+map_name+'/'+map_name+'_nearest.png'\n",
    "            cv2.imwrite(out_file_path0, result_image0)\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "\n",
    "            if split_multiprocessing == True:\n",
    "                with multiprocessing.Pool(int(PROCESSES*2)) as pool:\n",
    "                    callback = pool.starmap_async(extraction_step2_worker.extraction_step2_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, poly_counter, np.sum(img_bound), hsv_rb, rgb_rb, hsv_ms, rgb_ms, hsv_space, color_space[this_poly], ) for this_poly in range(0, poly_counter)])\n",
    "                    multiprocessing_results = callback.get()\n",
    "\n",
    "                    for legend, img_masked, this_updated_color_space in multiprocessing_results:\n",
    "                        # add masked result into private ans_category\n",
    "                        ans_category[legend] = np.copy(img_masked)\n",
    "                        # add mophological result into global ans_category\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        img_masked_morphology = cv2.morphologyEx(img_masked, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                        img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                        ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "                        \n",
    "                        color_space[legend] = np.copy(this_updated_color_space)\n",
    "\n",
    "            print('processing _v0 >>> _v2 (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "        print('time checkpoint _v2:', datetime.now()-runningtime_start)\n",
    "        running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "        if split_multiprocessing == True and poly_counter > 150: # split legends into multiple parts, multiprocessing for part of legends at a time => recommended if 'more than [around 150] legends in a map'\n",
    "            for_each_loop = for_each_loop_global\n",
    "            looping_times = math.ceil(poly_counter/for_each_loop)\n",
    "        else: # = direct multiprocessing for all legends at a time => recommended if runnable\n",
    "            looping_times = 1\n",
    "            for_each_loop = poly_counter\n",
    "        \n",
    "        for looping in range(0, looping_times):\n",
    "            range_min = 0 + for_each_loop*looping\n",
    "            range_max = min(for_each_loop + for_each_loop*looping, poly_counter)\n",
    "            print('looping... (round: '+str(looping+1)+'/'+str(looping_times)+')... (legend: '+str(range_min)+'-'+str(range_max)+' /'+str(poly_counter)+')')\n",
    "\n",
    "\n",
    "            for iteration_relaxing in range(0, 4):\n",
    "                global_solution = np.copy(ans_category[poly_counter])\n",
    "                global_solution[global_solution > 0] = 0\n",
    "                global_solution_empty = 255 - global_solution\n",
    "                global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                if split_multiprocessing == True:\n",
    "                    with multiprocessing.Pool(int(PROCESSES*2)) as pool:\n",
    "                        callback = pool.starmap_async(extraction_step3_worker.extraction_step3_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, rgb_ms, ans_category[this_poly], color_space[this_poly], iteration_relaxing, img_crop_black, img_crop_gray, global_solution_empty, ) for this_poly in range(range_min, range_max)])\n",
    "                        multiprocessing_results = callback.get()\n",
    "\n",
    "                        for legend, this_next_result in multiprocessing_results:\n",
    "                            # add masked result into private ans_category\n",
    "                            ans_category[legend] = np.copy(this_next_result)\n",
    "                            # add mophological result into global ans_category\n",
    "                            kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                            img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                            img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                            ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                print('processing _v2 >>> _v3 (iteration '+str(iteration_relaxing+1)+'/4)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "            print('time checkpoint _v3:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "            img_crop_black_and_gray = cv2.bitwise_or(img_crop_black, img_crop_gray)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # keep record of updated region\n",
    "            #updated_region = np.zeros(poly_counter)\n",
    "            updated_region = []\n",
    "            updated_for_relaxing = np.ones((ans_category[poly_counter].shape[0],ans_category[poly_counter].shape[1]),dtype=np.uint8)*255\n",
    "\n",
    "            # fill ip white pixel (remove noisy black pixel)\n",
    "            if poly_counter > 150: # MaybeEncodingError # Reason: MemoryError()\n",
    "                for iteration in range(0, 2):\n",
    "                    global_solution = np.copy(ans_category[poly_counter])\n",
    "                    global_solution_temp = np.copy(ans_category[poly_counter])\n",
    "                    global_solution_temp[global_solution_temp > 0] = 0\n",
    "                    global_solution_empty = 255 - global_solution_temp\n",
    "                    global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                    ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                    updating_counter_0 = 0\n",
    "                    updating_counter_1 = 0\n",
    "\n",
    "                    #updated_region = []\n",
    "                    next_updated_region = []\n",
    "\n",
    "                    if split_multiprocessing == True:\n",
    "                        with multiprocessing.Pool(int(PROCESSES/2)) as pool:\n",
    "                            if iteration == 0:\n",
    "                                callback = pool.starmap_async(extraction_step4_worker.extraction_step4_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, rgb_ms, None, ans_category[this_poly], color_space[this_poly], iteration, global_solution_empty, img_crop_black_and_gray, ) for this_poly in range(range_min, range_max)])\n",
    "                            else:\n",
    "                                callback = pool.starmap_async(extraction_step4_worker.extraction_step4_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, None, hsv_ms, ans_category[this_poly], color_space[this_poly], iteration, global_solution_empty, img_crop_black_and_gray, ) for this_poly in range(range_min, range_max)])\n",
    "                            multiprocessing_results = callback.get()\n",
    "                            \n",
    "                            for legend, this_next_result, updated_for_relaxing, polygon_updated in multiprocessing_results:\n",
    "                                if iteration == 0:\n",
    "                                    # add masked result into private ans_category\n",
    "                                    ans_category[legend] = np.copy(this_next_result)\n",
    "                                    # add mophological result into global ans_category\n",
    "                                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                                    img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                                    img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                                    ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                                    next_updated_region.append(np.copy(updated_for_relaxing))\n",
    "                                else:\n",
    "                                    if polygon_updated == True:\n",
    "                                        updating_counter_1 = updating_counter_1 + 1\n",
    "                                    updating_counter_0 = updating_counter_0 + 1\n",
    "                                \n",
    "                    print('processing _v3 >>> _v4 (iteration '+str(iteration+1)+'/2)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "                    updated_region = np.array(np.copy(next_updated_region))\n",
    "\n",
    "                    if iteration == 1:\n",
    "                        print(' - dynamic update ('+str(updating_counter_1)+' / '+str(updating_counter_0)+')')\n",
    "                ans_category_temp = np.copy(ans_category)\n",
    "            else:\n",
    "                for iteration in range(0, 2):\n",
    "                    global_solution = np.copy(ans_category[poly_counter])\n",
    "                    global_solution_temp = np.copy(ans_category[poly_counter])\n",
    "                    global_solution_temp[global_solution_temp > 0] = 0\n",
    "                    global_solution_empty = 255 - global_solution_temp\n",
    "                    global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                    ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                    updating_counter_0 = 0\n",
    "                    updating_counter_1 = 0\n",
    "\n",
    "                    #updated_region = []\n",
    "                    next_updated_region = []\n",
    "\n",
    "                    if split_multiprocessing == True:\n",
    "                        with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                            if iteration == 0:\n",
    "                                callback = pool.starmap_async(extraction_step4_worker.extraction_step4_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, rgb_ms, None, ans_category[this_poly], color_space[this_poly], iteration, global_solution_empty, img_crop_black_and_gray, ) for this_poly in range(range_min, range_max)])\n",
    "                            else:\n",
    "                                callback = pool.starmap_async(extraction_step4_worker.extraction_step4_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, None, hsv_ms, ans_category[this_poly], color_space[this_poly], iteration, global_solution_empty, img_crop_black_and_gray, ) for this_poly in range(range_min, range_max)])\n",
    "                            multiprocessing_results = callback.get()\n",
    "                            \n",
    "                            for legend, this_next_result, updated_for_relaxing, polygon_updated in multiprocessing_results:\n",
    "                                if iteration == 0:\n",
    "                                    # add masked result into private ans_category\n",
    "                                    ans_category[legend] = np.copy(this_next_result)\n",
    "                                    # add mophological result into global ans_category\n",
    "                                    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                                    img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                                    img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                                    ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                                    next_updated_region.append(np.copy(updated_for_relaxing))\n",
    "                                else:\n",
    "                                    if polygon_updated == True:\n",
    "                                        updating_counter_1 = updating_counter_1 + 1\n",
    "                                    updating_counter_0 = updating_counter_0 + 1\n",
    "                                \n",
    "                    print('processing _v3 >>> _v4 (iteration '+str(iteration+1)+'/2)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "                    updated_region = np.array(np.copy(next_updated_region))\n",
    "                    \n",
    "                    if iteration == 1:\n",
    "                        print(' - dynamic update ('+str(updating_counter_1)+' / '+str(updating_counter_0)+')')\n",
    "                ans_category_temp = np.copy(ans_category)\n",
    "\n",
    "            print('time checkpoint _v4:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            conv_kernel_set = []\n",
    "            conv_kernel_threshold0 = [1.0, 0.75, 0.75, 0.5, 0.5, 0.5, 0.5]#, 0.5, 0.5, 0.5]\n",
    "            conv_kernel_threshold = []\n",
    "\n",
    "            conv_kernel_0 = np.ones((3,3),dtype=np.uint8)\n",
    "            conv_kernel_0[1,1] = 0\n",
    "            conv_kernel_1 = np.ones((5,5),dtype=np.uint8)\n",
    "            conv_kernel_1[2,2] = 0\n",
    "            conv_kernel_2 = np.ones((7,7),dtype=np.uint8)\n",
    "            conv_kernel_2[2:5,2:5] = 0\n",
    "            conv_kernel_3 = np.ones((9,9),dtype=np.uint8)\n",
    "            conv_kernel_3[3:6,3:6] = 0\n",
    "            conv_kernel_4 = np.ones((11,11),dtype=np.uint8)\n",
    "            conv_kernel_4[3:8,3:8] = 0\n",
    "            conv_kernel_5 = np.ones((13,13),dtype=np.uint8)\n",
    "            conv_kernel_5[4:9,4:9] = 0\n",
    "            conv_kernel_6 = np.ones((15,15),dtype=np.uint8)\n",
    "            conv_kernel_6[4:11,4:11] = 0\n",
    "\n",
    "            conv_kernel_set.append(conv_kernel_0)\n",
    "            conv_kernel_set.append(conv_kernel_1)\n",
    "            conv_kernel_set.append(conv_kernel_2)\n",
    "            conv_kernel_set.append(conv_kernel_3)\n",
    "            conv_kernel_set.append(conv_kernel_4)\n",
    "            conv_kernel_set.append(conv_kernel_5)\n",
    "            conv_kernel_set.append(conv_kernel_6)\n",
    "\n",
    "            for conv_set in range(0, len(conv_kernel_set)):\n",
    "                conv_kernel_threshold.append(np.sum(conv_kernel_set[conv_set])*conv_kernel_threshold0[conv_set])\n",
    "\n",
    "\n",
    "\n",
    "            boundingRange = 3\n",
    "            masking0 = generate_mask(boundingRange)\n",
    "            masking = np.copy(masking0)\n",
    "            masking = masking.astype(float)\n",
    "\n",
    "            for direction in range(0, 8):\n",
    "                #print((masking[direction]==1.0).sum())\n",
    "                region_sum = (masking[direction]==1.0).sum()\n",
    "                for i, j in np.argwhere(masking[direction]==1.0):\n",
    "                    masking[direction][i][j] = (1.0/region_sum)\n",
    "\n",
    "\n",
    "            # keep record of updated region\n",
    "            #updated_region = np.zeros(poly_counter)\n",
    "            updated_region = []\n",
    "            updated_for_relaxing = np.ones((ans_category[poly_counter].shape[0],ans_category[poly_counter].shape[1]),dtype=np.uint8)*255\n",
    "\n",
    "            # fill ip white pixel (remove noisy black pixel)\n",
    "            for iteration in range(0, 1):\n",
    "                global_solution = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp = np.copy(ans_category[poly_counter])\n",
    "                global_solution_temp[global_solution_temp > 0] = 0\n",
    "                global_solution_empty = 255 - global_solution_temp\n",
    "                global_solution_empty = cv2.bitwise_and(global_solution_empty, img_bound)\n",
    "                ans_category[poly_counter] = np.zeros((img_rb.shape[0],img_rb.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                updating_counter_0 = 0\n",
    "                updating_counter_1 = 0\n",
    "\n",
    "                #updated_region = []\n",
    "                next_updated_region = []\n",
    "\n",
    "\n",
    "                if split_multiprocessing == True:\n",
    "                    with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                        if iteration == 0:\n",
    "                            callback = pool.starmap_async(extraction_step5_worker.extraction_step5_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, None, ans_category[this_poly], iteration, global_solution_empty, None, conv_kernel_set, conv_kernel_threshold, masking, ) for this_poly in range(range_min, range_max)]) # img_crop_black_and_gray\n",
    "                        else:\n",
    "                            callback = pool.starmap_async(extraction_step5_worker.extraction_step5_worker, [(this_poly, map_name, legend_name, solutiona_dir, print_intermediate_image, rgb_rb, hsv_ms, ans_category[this_poly], iteration, global_solution_empty, None, conv_kernel_set, conv_kernel_threshold, masking, ) for this_poly in range(range_min, range_max)])\n",
    "                        multiprocessing_results = callback.get()\n",
    "\n",
    "                        for legend, this_next_result, updated_for_relaxing, polygon_updated in multiprocessing_results:\n",
    "                            if iteration == 0:\n",
    "                                # add masked result into private ans_category\n",
    "                                ans_category[legend] = np.copy(this_next_result)\n",
    "                                # add mophological result into global ans_category\n",
    "                                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                                img_masked_morphology = cv2.morphologyEx(this_next_result, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                                img_masked_morphology[img_masked_morphology > 0] = legend+1\n",
    "                                ans_category[poly_counter] = cv2.add(ans_category[poly_counter], img_masked_morphology)\n",
    "\n",
    "                                next_updated_region.append(np.copy(updated_for_relaxing))\n",
    "                            else:\n",
    "                                if polygon_updated == True:\n",
    "                                    updating_counter_1 = updating_counter_1 + 1\n",
    "                                updating_counter_0 = updating_counter_0 + 1\n",
    "                            \n",
    "                print('processing _v4 >>> _v5 (iteration '+str(iteration+1)+'/1)... (legend '+str(legend+1)+'/'+str(poly_counter)+')... :', datetime.now()-runningtime_start)\n",
    "                updated_region = np.array(np.copy(next_updated_region))\n",
    "                \n",
    "                if iteration == 1:\n",
    "                    print(' - dynamic update ('+str(updating_counter_1)+' / '+str(updating_counter_0)+')')\n",
    "            #ans_category_updated = []\n",
    "            #ans_category_temp = np.copy(ans_category)\n",
    "            print('time checkpoint _v5:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "                \n",
    "            if poly_counter >= 5 and poly_counter <= 150:\n",
    "                print('proceed to text detection...')\n",
    "\n",
    "                img_backgroun_v0 = np.copy(img_rb)\n",
    "\n",
    "                lower_black_text = np.array([0,0,0])\n",
    "                upper_black_text = np.array([70,70,70])\n",
    "                mask_box_text0 = cv2.inRange(img_backgroun_v0, lower_black_text, upper_black_text)\n",
    "                res_box_text1 = cv2.bitwise_and(img_bound, img_bound, mask=mask_box_text0)\n",
    "                threshold_text = cv2.medianBlur(res_box_text1,3)\n",
    "\n",
    "                global_hsv_space = np.zeros((3, 400), dtype='uint8')\n",
    "                local_hsv_space = np.zeros((poly_counter, 3, 400), dtype='uint8')\n",
    "                #hsv_color_space = np.zeros((poly_counter, 2, 3), dtype='uint8')\n",
    "                hsv_color_space = []\n",
    "\n",
    "                global_hsv_space = np.zeros((3, 400), dtype='uint8')\n",
    "                local_hsv_space = np.zeros((poly_counter, 3, 400), dtype='uint8')\n",
    "                #hsv_color_space = np.zeros((poly_counter, 2, 3), dtype='uint8')\n",
    "                hsv_color_space = []\n",
    "\n",
    "                for legend in range(range_min, range_max): ###\n",
    "                    color_space_holder = []\n",
    "                    color_space_holder.append(color_space[legend][0])\n",
    "                    color_space_holder.append(color_space[legend][1])\n",
    "\n",
    "                    this_hsv_color_space = np.copy(color_space_holder)\n",
    "                    #hsv_color_space[legend] = np.copy(color_space_holder)\n",
    "                    hsv_color_space.append(color_space_holder)\n",
    "                    #print(legend_name[legend], color_space_holder, hsv_color_space[legend][1], this_hsv_color_space)\n",
    "\n",
    "                    global_hsv_space[0][max(this_hsv_color_space[0][0]-1, 0): 1+this_hsv_color_space[1][0]+1] += 1 # h space\n",
    "                    global_hsv_space[1][max(this_hsv_color_space[0][1]-15, 0): 1+this_hsv_color_space[1][1]+15] += 1 # s space\n",
    "                    global_hsv_space[2][max(this_hsv_color_space[0][2]-15, 0): 1+this_hsv_color_space[1][2]+15] += 1 # v space\n",
    "                    local_hsv_space[legend][0][max(this_hsv_color_space[0][0]-1, 0): 1+this_hsv_color_space[1][0]+1] = 1 # h space\n",
    "                    local_hsv_space[legend][1][max(this_hsv_color_space[0][1]-15, 0): 1+this_hsv_color_space[1][1]+15] = 1 # s space\n",
    "                    local_hsv_space[legend][2][max(this_hsv_color_space[0][2]-15, 0): 1+this_hsv_color_space[1][2]+15] = 1 # v space\n",
    "\n",
    "                #print('legend loaded...')\n",
    "\n",
    "                print('time checkpoint _text_v0:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "                \n",
    "                if split_multiprocessing == True:\n",
    "                    with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                        callback = pool.starmap_async(extraction_step6_pre_update_worker.extraction_step6_pre_update_worker, [(this_poly, ans_category[this_poly], ) for this_poly in range(range_min, range_max)])\n",
    "                        multiprocessing_results = callback.get()\n",
    "\n",
    "                        for legend, return_image, unique_counter in multiprocessing_results:\n",
    "                            if unique_counter != 2:\n",
    "                                print('extract nothing...')\n",
    "                                return_image = np.copy(img_bound)\n",
    "                            ans_category[legend] = np.copy(return_image)\n",
    "                #print('v6 updated...')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                comparison_needed = []\n",
    "                comparison_target = np.empty(poly_counter, dtype=object)\n",
    "                if split_multiprocessing == True:\n",
    "                    with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                        callback = pool.starmap_async(extraction_step6_specify_overlap_legend_worker.extraction_step6_specify_overlap_legend_worker, [(this_poly, legend_name, hsv_color_space[this_poly], local_hsv_space, global_hsv_space[0], range_min, range_max, ) for this_poly in range(range_min, range_max)])\n",
    "                        multiprocessing_results = callback.get()\n",
    "\n",
    "                        for legend, candidate_similar_legend_1, candidate_similar_legend_2 in multiprocessing_results:\n",
    "                            similar_legend = []\n",
    "\n",
    "                            for counter_legend in candidate_similar_legend_1:\n",
    "                                if np.mean(ans_category[legend]) > 0 and np.mean(ans_category[counter_legend]) > 0:\n",
    "                                    ans_overlap = cv2.bitwise_and(ans_category[legend], ans_category[counter_legend])\n",
    "                                    if (np.mean(ans_overlap) / np.mean(ans_category[legend])) > 0.66 and (np.mean(ans_overlap) / np.mean(ans_category[counter_legend])) > 0.66:\n",
    "                                        # if there are few overlaps in v6 extracted answer, than we don't need text detection\n",
    "                                        #print('we need to compare them')\n",
    "                                        #print('overlapping issue with large area: '+legend_name[legend]+' <-> '+legend_name[counter_legend])\n",
    "                                        similar_legend.append(counter_legend)\n",
    "\n",
    "                            for counter_legend in candidate_similar_legend_2:\n",
    "                                ans_overlap = cv2.bitwise_and(ans_category[legend], ans_category[counter_legend])\n",
    "                                if np.mean(ans_category[legend]) > 0 and np.mean(ans_category[counter_legend]) > 0:\n",
    "                                    if (np.mean(ans_overlap) / np.mean(ans_category[legend])) > 0.2 and (np.mean(ans_overlap) / np.mean(ans_category[counter_legend])) > 0.2:\n",
    "                                        # if there are few overlaps in v6 extracted answer, than we don't need text detection\n",
    "                                        #print('we need to compare them')\n",
    "                                        #print('overlapping issue with similar color: '+legend_name[legend]+' <-> '+legend_name[counter_legend])\n",
    "                                        similar_legend.append(counter_legend)\n",
    "\n",
    "                            comparison_target[legend] = np.copy(similar_legend)\n",
    "                            if len(similar_legend) > 0:\n",
    "                                comparison_needed.append(legend)\n",
    "                #print(comparison_target)\n",
    "                print(comparison_needed)\n",
    "                print('time checkpoint _text_v1:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "                global_res_probability = np.empty(poly_counter, dtype=object)\n",
    "                global_confidence = np.empty(poly_counter, dtype=object)\n",
    "\n",
    "\n",
    "                # multiprocessing\n",
    "                list_for_multiprocessing = []\n",
    "                for list_id in range(0, len(comparison_needed)):\n",
    "                    legend = comparison_needed[list_id]\n",
    "                    list_for_multiprocessing.append(legend)\n",
    "\n",
    "                if split_multiprocessing == True:\n",
    "                    with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                        callback = pool.starmap_async(extraction_step6_find_legend_in_map_worker.extraction_step6_find_legend_in_map_worker, [(this_poly, map_name, legend_name, solutiona_dir, threshold_text, None, np.sum(img_bound), True, print_intermediate_image, ) for this_poly in list_for_multiprocessing])\n",
    "                        multiprocessing_results = callback.get()\n",
    "\n",
    "                        for legend, threshold, update_image_space in multiprocessing_results:\n",
    "                            # legend, res, confidence_placeholder = this_poly.get()\n",
    "                            # global_res_probability[legend] = np.copy(res)\n",
    "                            # global_confidence[legend] = np.copy(confidence_placeholder)\n",
    "\n",
    "                            #legend, res = this_poly.get()\n",
    "                            global_res_probability[legend] = np.copy(update_image_space)\n",
    "                            loc_arg = np.argwhere(update_image_space >= 255*threshold)\n",
    "                            global_confidence[legend] = np.copy(loc_arg)\n",
    "                print('time checkpoint _text_v2:', datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "                # multiprocessing\n",
    "                temp_ans_category = np.copy(ans_category)\n",
    "                list_for_multiprocessing = []\n",
    "                for list_id in range(0, len(comparison_needed)):\n",
    "                    legend = comparison_needed[list_id]\n",
    "                    list_for_multiprocessing.append(legend)\n",
    "                print(list_for_multiprocessing)\n",
    "\n",
    "\n",
    "                if split_multiprocessing == True:\n",
    "                    def generate_cluster_sequential(legend, input_image, blur_radius_initial, blur_radius_step):\n",
    "                        # smooth the image (to remove small objects)\n",
    "                        blur_radius = blur_radius_initial\n",
    "                        threshold_blur = 0\n",
    "                        imgf = ndimage.gaussian_filter(input_image, blur_radius)\n",
    "\n",
    "                        # find connected components\n",
    "                        labeled, nr_objects = ndimage.label(imgf > threshold_blur)\n",
    "\n",
    "                        while nr_objects > 100:\n",
    "                            # smooth the image (to remove small objects)\n",
    "                            blur_radius = blur_radius + blur_radius_step\n",
    "                            threshold_blur = 0\n",
    "                            imgf = ndimage.gaussian_filter(input_image, blur_radius)\n",
    "\n",
    "                            # find connected components\n",
    "                            labeled, nr_objects = ndimage.label(imgf > threshold_blur)\n",
    "\n",
    "                        return labeled, nr_objects\n",
    "\n",
    "\n",
    "                    for legend in list_for_multiprocessing:\n",
    "                        updated_region = np.copy(ans_category[legend])\n",
    "                        updated_region_rollback = np.copy(updated_region)\n",
    "\n",
    "                        try:\n",
    "                            with multiprocessing.Pool(int(PROCESSES)) as pool:\n",
    "                                callback = pool.starmap_async(extraction_step6_compare_against_competitor_worker.update_based_on_text, [(legend, counter_legend, ans_category[legend], ans_category[counter_legend], global_confidence[legend], global_confidence[counter_legend], global_res_probability[legend], global_res_probability[counter_legend], img_boundary, ) for counter_legend in comparison_target[legend]]) # img_crop_black\n",
    "                                multiprocessing_results = callback.get()\n",
    "\n",
    "                                for this_legend, this_counter_legend, img_ans_v1 in multiprocessing_results:\n",
    "                                    ban_region = cv2.subtract(ans_category[legend], img_ans_v1)\n",
    "                                    updated_region = cv2.subtract(updated_region, ban_region)\n",
    "                        \n",
    "                        except OSError:\n",
    "                            print('OSError... Run Sequential Processing Instead...')\n",
    "\n",
    "                            # Sequential processing\n",
    "                            updated_region = np.copy(updated_region_rollback)\n",
    "\n",
    "                            # Sequential processing\n",
    "                            for counter_legend in comparison_target[legend]:\n",
    "                                img_ans_v0 = np.copy(ans_category[legend])\n",
    "                                #save_region_temp = cv2.subtract(ans_category_this_legend, ans_category[counter_legend])\n",
    "                                temp_competitor = 255 - ans_category[counter_legend]\n",
    "                                save_region_temp = cv2.bitwise_and(ans_category[legend], temp_competitor)\n",
    "                                img_ans_v0 = cv2.subtract(img_ans_v0, save_region_temp)\n",
    "\n",
    "                                labeled, nr_objects = generate_cluster_sequential(legend, img_ans_v0, 15.0, 5.0)\n",
    "\n",
    "                                depot_checked_polygon = np.zeros((labeled.shape[0],labeled.shape[1]),dtype=np.uint8)\n",
    "\n",
    "                                depot_got = 0\n",
    "                                distance_threshold = 300\n",
    "\n",
    "                                for object_traverse in range(1, nr_objects):\n",
    "                                    cluster_object = np.argwhere(labeled == object_traverse)\n",
    "                                    if cluster_object.shape[0] == 0:\n",
    "                                        continue\n",
    "\n",
    "                                    center_x = np.mean(cluster_object, axis=0)[0]\n",
    "                                    center_y = np.mean(cluster_object, axis=0)[1]\n",
    "\n",
    "                                    belong_to_other_group = False\n",
    "                                    belong_to_this_group = False\n",
    "\n",
    "                                    # The text located 'in' this polygon => include\n",
    "                                    in_polygon_arg = np.logical_and(labeled[0:global_res_probability[legend].shape[0], 0:global_res_probability[legend].shape[1]] == object_traverse, global_res_probability[legend] >= 0.5)\n",
    "                                    in_polygon_bool = (True in in_polygon_arg)\n",
    "                                    if in_polygon_bool == True:\n",
    "                                        belong_to_other_group = False\n",
    "                                        belong_to_this_group = True\n",
    "\n",
    "                                    # The text located 'nearby' this polygon => include (especially for small polygons, where legends are labeled outside)\n",
    "                                    if belong_to_other_group == False:\n",
    "                                        center_placeholder = np.array([[center_x, center_y]])\n",
    "                                        center_placeholder = np.repeat(center_placeholder, len(global_confidence[legend]), axis=0)\n",
    "                                        distances_2_depot = np.sqrt(np.sum((global_confidence[legend]-center_placeholder)**2,axis=1))\n",
    "                                        min_distance_to_self = np.min(distances_2_depot)\n",
    "                                        \n",
    "                                        if min_distance_to_self < distance_threshold:\n",
    "                                            belong_to_other_group = False\n",
    "                                            belong_to_this_group = True\n",
    "\n",
    "                                    # The counter-text located 'in' this polygon => exclude\n",
    "                                    if belong_to_other_group == False:\n",
    "                                        center_placeholder = np.array([[center_x, center_y]])\n",
    "                                        center_placeholder = np.repeat(center_placeholder, len(global_confidence[counter_legend]), axis=0)\n",
    "                                        distances_2_depot = np.sqrt(np.sum((global_confidence[counter_legend]-center_placeholder)**2,axis=1))\n",
    "                                        min_distance_to_counter = np.min(distances_2_depot)\n",
    "                                        \n",
    "                                        in_polygon_arg = np.logical_and(labeled[0:global_res_probability[counter_legend].shape[0], 0:global_res_probability[counter_legend].shape[1]] == object_traverse, global_res_probability[counter_legend] >= 0.75)\n",
    "                                        in_polygon_bool = (True in in_polygon_arg)\n",
    "                                        if in_polygon_bool == True:\n",
    "                                            belong_to_other_group = True\n",
    "                                            belong_to_this_group = False\n",
    "                                        \n",
    "\n",
    "                                    if belong_to_other_group == False and belong_to_this_group == False:\n",
    "                                        #if min_distance_to_self/confidence_to_self < (min_distance_to_counter/confidence_to_counter)*1.33:\n",
    "                                        if min_distance_to_self < (min_distance_to_counter)*2.0:\n",
    "                                            belong_to_this_group = True\n",
    "\n",
    "\n",
    "                                    if belong_to_this_group == True and belong_to_other_group == False :\n",
    "                                        # create a mask to only preserve current legend color in the basemap\n",
    "                                        depot_checked_polygon_0 = np.zeros((labeled.shape[0],labeled.shape[1]),dtype=np.uint8)\n",
    "                                        depot_checked_polygon_0[np.logical_and(labeled==object_traverse, ans_category[legend]>0)] = 255\n",
    "                                        depot_checked_polygon_0 = cv2.bitwise_and(depot_checked_polygon_0, ans_category[legend])\n",
    "                                        depot_checked_polygon = cv2.bitwise_or(depot_checked_polygon, depot_checked_polygon_0)\n",
    "                                        depot_got = depot_got+1\n",
    "\n",
    "\n",
    "                                #print('updated against - '+legend_name[counter_legend])\n",
    "                                #plt.imshow(save_region_temp)\n",
    "                                #plt.show()\n",
    "                                #plt.imshow(depot_checked_polygon)\n",
    "                                #plt.show()\n",
    "                                img_ans_v1 = cv2.bitwise_and(ans_category[legend], depot_checked_polygon)\n",
    "                                img_ans_v1 = cv2.bitwise_or(img_ans_v1, save_region_temp)\n",
    "                                #plt.imshow(img_ans_v1)\n",
    "                                #plt.show()\n",
    "\n",
    "                                # return legend, counter_legend, img_ans_v1\n",
    "                                ban_region = cv2.subtract(ans_category[legend], img_ans_v1)\n",
    "                                updated_region = cv2.subtract(updated_region, ban_region)\n",
    "\n",
    "                                \n",
    "\n",
    "                        # remove noisy white pixel\n",
    "                        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "                        opening = cv2.morphologyEx(updated_region, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                        updated_region=cv2.threshold(opening, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "                        \n",
    "                        if poly_counter <= 30:\n",
    "                            if np.unique(updated_region).shape[0] != 2 or (np.sum(updated_region)/np.unique(updated_region)[1]) / (np.sum(ans_category[legend])/np.unique(ans_category[legend])[1]) < 0.0005:\n",
    "                                print(legend_name[legend]+' rollback...')\n",
    "                                updated_region = np.copy(ans_category[legend])\n",
    "                        else:\n",
    "                            if np.unique(updated_region).shape[0] != 2 or (np.sum(updated_region)/np.unique(updated_region)[1]) / (np.sum(ans_category[legend])/np.unique(ans_category[legend])[1]) < 0.0001:\n",
    "                                print(legend_name[legend]+' rollback...')\n",
    "                                updated_region = np.copy(ans_category[legend])\n",
    "\n",
    "\n",
    "                        if print_intermediate_image == True:\n",
    "                            out_file_path000=os.path.join(solutiona_dir+'intermediate7(2)', map_name, map_name+'_'+legend_name[legend]+'_poly_v6.png')\n",
    "                            cv2.imwrite(out_file_path000, updated_region)\n",
    "                        \n",
    "                        temp_ans_category[legend] = np.copy(updated_region) ### updated v6 to v7 (3/3)\n",
    "\n",
    "                        print('processing _v2(t) >>> _v3(t) (selected legend '+str(legend)+'/'+str(list_for_multiprocessing)+')... :', datetime.now()-runningtime_start)\n",
    "                        \n",
    "                    print('time checkpoint _text_v3:', datetime.now()-runningtime_start)\n",
    "                    running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "                print('text detection finished...')\n",
    "                ans_category = np.copy(temp_ans_category)\n",
    "\n",
    "            else:\n",
    "                print('no text detection needed...')\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "                running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # multiprocessing_step7\n",
    "            finisher_counter = 0\n",
    "            if split_multiprocessing == True:\n",
    "                with multiprocessing.Pool(PROCESSES) as pool:\n",
    "                    callback = pool.starmap_async(extraction_step7_worker.extraction_step7_worker, [(this_poly, map_name, legend_name, solutiona_dir, file_path, ans_category[this_poly], img_bound, ) for this_poly in range(range_min, range_max)])\n",
    "                    multiprocessing_results = callback.get()\n",
    "\n",
    "                    for legend, pred_binary_raster in multiprocessing_results:\n",
    "                        #legend, pred_binary_raster = this_poly.get()\n",
    "                        # doing nothing\n",
    "                        finisher_counter = finisher_counter + 1\n",
    "            '''\n",
    "            else:\n",
    "                for this_poly in range(range_min, range_max):\n",
    "                    legend, pred_binary_raster = extraction_step6, (this_poly)\n",
    "            '''\n",
    "\n",
    "            print('time checkpoint _v7:', datetime.now()-runningtime_start)\n",
    "            running_time_v.append(datetime.now()-runningtime_start)\n",
    "\n",
    "\n",
    "\n",
    "        if os.path.isfile(solutiona_dir+'intermediate7(2)/'+'running_time_record_v3.csv') == False:\n",
    "            with open(solutiona_dir+'intermediate7(2)/'+'running_time_record_v3.csv','w') as fd:\n",
    "                fd.write('File,checkpoint_0,checkpoint_1,checkpoint_2,checkpoint_3,checkpoint_4,checkpoint_5,checkpoint_t0,checkpoint_t1,checkpoint_t2,checkpoint_t3,checkpoint_7,\\n')\n",
    "                fd.close()\n",
    "        with open(solutiona_dir+'intermediate7(2)/'+'running_time_record_v3.csv','a') as fd:\n",
    "            fd.write(map_name+',')\n",
    "            for rtc in range(0, len(running_time_v)):\n",
    "                fd.write(str(running_time_v[rtc])+',')\n",
    "            fd.write('\\n')\n",
    "            fd.close()\n",
    "\n",
    "# 589m 21.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e353a3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
